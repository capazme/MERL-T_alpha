"""
Experiment Tracker
==================

A/B testing e tracking esperimenti per pesi.

L'ExperimentTracker gestisce:
1. Creazione esperimenti con varianti (control/treatment)
2. Assegnazione utenti a varianti
3. Raccolta metriche per variante
4. Analisi statistica (p-value, effect size)

Esempio:
    >>> tracker = ExperimentTracker(store)
    >>> exp = await tracker.create_experiment(
    ...     name="alpha_tuning",
    ...     variants={
    ...         "control": WeightConfig(retrieval=RetrievalWeights(alpha=0.7)),
    ...         "treatment": WeightConfig(retrieval=RetrievalWeights(alpha=0.8))
    ...     }
    ... )
    >>> variant = await tracker.assign_variant(exp.id, user_id="user123")
    >>> await tracker.record_outcome(exp.id, variant, {"mrr": 0.85})
"""

import structlog
from typing import Dict, Optional, List, Any
from dataclasses import dataclass, field
from datetime import datetime
from uuid import uuid4
import hashlib
import random

from merlt.weights.config import WeightConfig, ExperimentConfig, ExperimentVariant
from merlt.weights.store import WeightStore

log = structlog.get_logger()


@dataclass
class Experiment:
    """
    Rappresenta un esperimento A/B attivo.

    Attributes:
        id: ID univoco esperimento
        name: Nome descrittivo
        status: Stato (draft, running, completed, stopped)
        variants: Varianti con configurazioni pesi
        created_at: Timestamp creazione
        metrics_by_variant: Metriche raccolte per variante
    """
    id: str
    name: str
    description: Optional[str] = None
    status: str = "draft"
    variants: Dict[str, WeightConfig] = field(default_factory=dict)
    allocation: Dict[str, float] = field(default_factory=dict)
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    completed_at: Optional[str] = None
    metrics_by_variant: Dict[str, List[Dict[str, float]]] = field(default_factory=dict)
    user_assignments: Dict[str, str] = field(default_factory=dict)


@dataclass
class ExperimentAnalysis:
    """
    Risultati analisi esperimento.

    Attributes:
        experiment_id: ID esperimento
        control_metrics: Metriche aggregate control
        treatment_metrics: Metriche aggregate treatment
        winner: Variante vincente (o None se inconclusive)
        p_value: p-value del test statistico
        effect_size: Cohen's d effect size
        significant: Se la differenza e' statisticamente significativa
    """
    experiment_id: str
    control_metrics: Dict[str, float]
    treatment_metrics: Dict[str, float]
    winner: Optional[str] = None
    p_value: Optional[float] = None
    effect_size: Optional[float] = None
    significant: bool = False
    samples_control: int = 0
    samples_treatment: int = 0


class ExperimentTracker:
    """
    Gestisce A/B testing sui pesi del sistema.

    Supporta:
    - Creazione esperimenti multi-variante
    - Assegnazione deterministica utenti (hash-based)
    - Raccolta metriche per variante
    - Analisi statistica semplice

    Esempio:
        >>> tracker = ExperimentTracker(store)
        >>>
        >>> # Crea esperimento
        >>> exp = await tracker.create_experiment(
        ...     name="alpha_test",
        ...     control_weights=config_a,
        ...     treatment_weights=config_b,
        ...     split_ratio=0.5
        ... )
        >>>
        >>> # Assegna utente
        >>> variant = await tracker.assign_variant(exp.id, "user123")
        >>> # "control" o "treatment"
        >>>
        >>> # Registra outcome
        >>> await tracker.record_outcome(exp.id, variant, {"mrr": 0.85})
        >>>
        >>> # Analizza
        >>> analysis = await tracker.analyze_experiment(exp.id)
    """

    def __init__(self, store: WeightStore):
        """
        Inizializza ExperimentTracker.

        Args:
            store: WeightStore per persistenza
        """
        self.store = store
        self._experiments: Dict[str, Experiment] = {}

        log.info("ExperimentTracker initialized")

    async def create_experiment(
        self,
        name: str,
        control_weights: WeightConfig,
        treatment_weights: WeightConfig,
        split_ratio: float = 0.5,
        description: Optional[str] = None
    ) -> Experiment:
        """
        Crea un nuovo esperimento A/B.

        Args:
            name: Nome esperimento
            control_weights: Configurazione pesi control
            treatment_weights: Configurazione pesi treatment
            split_ratio: % traffico per treatment (default 50%)
            description: Descrizione opzionale

        Returns:
            Experiment creato
        """
        exp_id = str(uuid4())[:8]

        experiment = Experiment(
            id=exp_id,
            name=name,
            description=description,
            status="running",
            variants={
                "control": control_weights,
                "treatment": treatment_weights,
            },
            allocation={
                "control": 1 - split_ratio,
                "treatment": split_ratio,
            },
            metrics_by_variant={
                "control": [],
                "treatment": [],
            }
        )

        self._experiments[exp_id] = experiment

        log.info(
            "Experiment created",
            experiment_id=exp_id,
            name=name,
            split_ratio=split_ratio
        )

        return experiment

    async def assign_variant(
        self,
        experiment_id: str,
        user_id: str
    ) -> str:
        """
        Assegna un utente a una variante.

        L'assegnazione e' deterministica (basata su hash) per garantire
        che lo stesso utente veda sempre la stessa variante.

        Args:
            experiment_id: ID esperimento
            user_id: ID utente

        Returns:
            Nome variante ("control" o "treatment")
        """
        if experiment_id not in self._experiments:
            raise ValueError(f"Experiment {experiment_id} not found")

        exp = self._experiments[experiment_id]

        # Check cache
        if user_id in exp.user_assignments:
            return exp.user_assignments[user_id]

        # Deterministic assignment via hash
        hash_input = f"{experiment_id}:{user_id}"
        hash_value = int(hashlib.md5(hash_input.encode()).hexdigest(), 16)
        normalized = (hash_value % 10000) / 10000  # [0, 1)

        # Assign based on allocation
        if normalized < exp.allocation.get("treatment", 0.5):
            variant = "treatment"
        else:
            variant = "control"

        # Cache assignment
        exp.user_assignments[user_id] = variant

        log.debug(
            "User assigned to variant",
            experiment_id=experiment_id,
            user_id=user_id[:8] + "...",
            variant=variant
        )

        return variant

    async def get_weights_for_user(
        self,
        experiment_id: str,
        user_id: str
    ) -> WeightConfig:
        """
        Ottiene i pesi per un utente in un esperimento.

        Args:
            experiment_id: ID esperimento
            user_id: ID utente

        Returns:
            WeightConfig per la variante assegnata
        """
        variant = await self.assign_variant(experiment_id, user_id)
        exp = self._experiments[experiment_id]
        return exp.variants[variant]

    async def record_outcome(
        self,
        experiment_id: str,
        variant: str,
        metrics: Dict[str, float]
    ) -> None:
        """
        Registra outcome per una variante.

        Args:
            experiment_id: ID esperimento
            variant: Nome variante
            metrics: Metriche da registrare (es. {"mrr": 0.85, "recall": 0.9})
        """
        if experiment_id not in self._experiments:
            raise ValueError(f"Experiment {experiment_id} not found")

        exp = self._experiments[experiment_id]

        if variant not in exp.metrics_by_variant:
            raise ValueError(f"Variant {variant} not in experiment")

        exp.metrics_by_variant[variant].append(metrics)

        log.debug(
            "Outcome recorded",
            experiment_id=experiment_id,
            variant=variant,
            metrics=metrics
        )

    async def analyze_experiment(
        self,
        experiment_id: str
    ) -> ExperimentAnalysis:
        """
        Analizza risultati esperimento.

        Calcola:
        - Metriche aggregate per variante
        - p-value via t-test (se abbastanza campioni)
        - Effect size (Cohen's d)
        - Winner (se significativo)

        Args:
            experiment_id: ID esperimento

        Returns:
            ExperimentAnalysis con risultati
        """
        if experiment_id not in self._experiments:
            raise ValueError(f"Experiment {experiment_id} not found")

        exp = self._experiments[experiment_id]

        control_metrics = self._aggregate_metrics(exp.metrics_by_variant.get("control", []))
        treatment_metrics = self._aggregate_metrics(exp.metrics_by_variant.get("treatment", []))

        n_control = len(exp.metrics_by_variant.get("control", []))
        n_treatment = len(exp.metrics_by_variant.get("treatment", []))

        # Simple analysis (senza scipy per ora)
        p_value = None
        effect_size = None
        winner = None
        significant = False

        # Check if we have enough samples
        min_samples = 30
        if n_control >= min_samples and n_treatment >= min_samples:
            # Calcola effect size semplice per MRR (se presente)
            if "mrr" in control_metrics and "mrr" in treatment_metrics:
                diff = treatment_metrics["mrr"] - control_metrics["mrr"]

                # Stima effect size (semplificato)
                effect_size = abs(diff)

                # Winner semplice (>5% improvement)
                if diff > 0.05:
                    winner = "treatment"
                    significant = True
                elif diff < -0.05:
                    winner = "control"
                    significant = True

        analysis = ExperimentAnalysis(
            experiment_id=experiment_id,
            control_metrics=control_metrics,
            treatment_metrics=treatment_metrics,
            winner=winner,
            p_value=p_value,
            effect_size=effect_size,
            significant=significant,
            samples_control=n_control,
            samples_treatment=n_treatment,
        )

        log.info(
            "Experiment analyzed",
            experiment_id=experiment_id,
            samples_control=n_control,
            samples_treatment=n_treatment,
            winner=winner,
            significant=significant
        )

        return analysis

    def _aggregate_metrics(self, metrics_list: List[Dict[str, float]]) -> Dict[str, float]:
        """Aggrega lista di metriche in valori medi."""
        if not metrics_list:
            return {}

        aggregated = {}
        for key in metrics_list[0].keys():
            values = [m.get(key, 0) for m in metrics_list if key in m]
            if values:
                aggregated[key] = sum(values) / len(values)

        return aggregated

    async def stop_experiment(self, experiment_id: str) -> Experiment:
        """
        Ferma un esperimento.

        Args:
            experiment_id: ID esperimento

        Returns:
            Experiment aggiornato
        """
        if experiment_id not in self._experiments:
            raise ValueError(f"Experiment {experiment_id} not found")

        exp = self._experiments[experiment_id]
        exp.status = "stopped"
        exp.completed_at = datetime.now().isoformat()

        log.info("Experiment stopped", experiment_id=experiment_id)
        return exp

    async def complete_experiment(
        self,
        experiment_id: str,
        winner: Optional[str] = None
    ) -> Experiment:
        """
        Completa un esperimento e (opzionalmente) applica il winner.

        Args:
            experiment_id: ID esperimento
            winner: Variante da applicare come nuovi pesi default

        Returns:
            Experiment aggiornato
        """
        if experiment_id not in self._experiments:
            raise ValueError(f"Experiment {experiment_id} not found")

        exp = self._experiments[experiment_id]
        exp.status = "completed"
        exp.completed_at = datetime.now().isoformat()

        # Se winner specificato, salva come nuovi pesi
        if winner and winner in exp.variants:
            await self.store.save_weights(
                config=exp.variants[winner],
                experiment_id=f"{experiment_id}_winner",
                metrics=self._aggregate_metrics(exp.metrics_by_variant.get(winner, []))
            )
            log.info(
                "Experiment completed, winner applied",
                experiment_id=experiment_id,
                winner=winner
            )
        else:
            log.info("Experiment completed", experiment_id=experiment_id)

        return exp

    def list_experiments(self, status: Optional[str] = None) -> List[Experiment]:
        """Lista tutti gli esperimenti."""
        experiments = list(self._experiments.values())
        if status:
            experiments = [e for e in experiments if e.status == status]
        return experiments

    def get_experiment(self, experiment_id: str) -> Optional[Experiment]:
        """Ottiene un esperimento per ID."""
        return self._experiments.get(experiment_id)
