# Prossimi Passi - Roadmap di Sviluppo

**Data Ultimo Aggiornamento:** 2025-11-06 (Week 7 Completion Update)
**Commit:** Week 7 Complete - Preprocessing Integration into LangGraph Workflow
**Branch:** `develop`
**Status:** Phase 1 Complete + Week 3-5-6-7 Complete (75% implementato)

---

## ðŸ“ˆ PROGRESSO GLOBALE

**Linee di Codice Totali:**
- **Phase 1 (RLCF Core):** 15,635 linee (backend + frontend + tests)
  - Backend: 9,885 linee
  - Frontend: ~3,000 linee
  - Tests: ~2,750 linee

- **Phase 2 Week 3 (KG + Pipeline):** +9,000 linee
  - Backend Production: ~3,920 linee (preprocessing + orchestration)
  - Backend Integration: ~330 linee (pipeline_integration.py)
  - Backend RLCF Extension: ~520 linee (rlcf_feedback_processor.py)
  - Tests & Documentation: ~3,000+ linee

- **Phase 2 Week 5 Day 1-2 (Document Ingestion):** +4,100 linee
  - Backend Production: ~2,500 linee (document_ingestion package + CLI)
  - Documentation: ~1,600 linee (README, design doc, week summary)

- **Week 6 (Orchestration Layer):** +18,287 linee âœ… NEW
  - LLM Router + Config: ~4,000 linee
  - Retrieval Agents (KG, API, VectorDB): ~3,200 linee
  - Reasoning Experts + Synthesizer: ~3,400 linee
  - Iteration Controller: ~1,530 linee
  - LangGraph Workflow + REST API: ~4,856 linee
  - Test Suite: ~1,301 linee

- **Week 7 (Preprocessing Integration):** +5,838 linee âœ… NEW
  - Interface Unification: ~688 linee (kg_enrichment, workflow, config)
  - Test Suite: ~1,650 linee (33 test cases across 3 files)
  - Documentation: ~3,500 linee (WEEK7_PREPROCESSING_COMPLETE.md)

**TOTAL PROGETTO: ~52,860 linee (incluso Week 7)**

**Test Coverage:**
- Phase 1: 85%+ on core RLCF
- Phase 2 Week 3: 100+ test cases, 3,000+ LOC
- Week 6: 64+ test cases, 1,301 LOC
- Week 7: 33 test cases, 1,650 LOC

**Completion Status:**
- âœ… Phase 1: 100% Complete (RLCF Core)
- âœ… Phase 2 Week 3: 100% Complete (KG + Pipeline Integration)
- âœ… Phase 2 Week 5 Day 1-2: 100% Complete (Document Ingestion)
- âœ… Week 6: 100% Complete (Orchestration Layer)
- âœ… Week 7: 100% Complete (Preprocessing Integration)
- â³ Week 8: Next (Database + Query Understanding LLM)
- âŒ Phase 3-6: Not Started

---

## ðŸ“Š Stato Attuale del Progetto - ANALISI DETTAGLIATA

### âœ… Completato (Phase 1 - RLCF Core)

#### **Backend Implementation** (9,885 linee di codice)

**Core Modules** (26 file Python):
- âœ… **models.py** (204 righe): 9 modelli SQLAlchemy 2.0 async - User, Credential, LegalTask, Response, Feedback, FeedbackRating, BiasReport, DevilsAdvocateAssignment, TaskAssignment, AccountabilityReport
- âœ… **main.py** (1,620+ righe): FastAPI app con 50+ endpoints REST, CORS middleware, startup/shutdown events
- âœ… **authority_module.py** (184 righe): Formula `A_u(t) = Î±Â·B_u + Î²Â·T_u(t-1) + Î³Â·P_u(t)` completamente implementata
- âœ… **aggregation_engine.py** (253 righe): Algoritmo uncertainty-preserving con Shannon entropy
- âœ… **bias_analysis.py** (476 righe): 3 tipi di bias detection (Professional Clustering, Geographic, Temporal)
- âœ… **ai_service.py** (342 righe): OpenRouter integration con retry logic e streaming
- âœ… **config.py** (59 righe): YAML config loader (model_config.yaml, task_config.yaml)
- âœ… **config_manager.py** (420 righe): Hot-reload system con watchdog, backup/restore, thread-safe singleton
- âœ… **export_dataset.py** (190 righe): JSONL/CSV export per SFT e Preference Learning
- âœ… **validation.py** (223 righe): Schema validation per task types
- âœ… **dependencies.py** (54 righe): FastAPI dependency injection
- âœ… **devils_advocate.py** (319 righe): Sistema Devil's Advocate per RLCF
- âœ… **post_processing.py** (61 righe): Post-processing pipeline
- âœ… **training_scheduler.py** (174 righe): Training cycle scheduler
- âœ… **seed_data.py** (304 righe): Demo data seeding

**Task Handlers** (4 file, 2,022 righe):
- âœ… **base.py** (124 righe): Abstract BaseTaskHandler con Strategy pattern
- âœ… **classification_handler.py** (136 righe): Document classification
- âœ… **qa_handler.py** (1,437 righe): 8 handler specializzati (QA, Summarization, Prediction, NLI, NER, Drafting, RiskSpotting, DoctrineApplication, StatutoryRuleQA)
- âœ… **retrieval_validation_handler.py** (325 righe): **NUOVO** - Validazione retrieval quality con Jaccard similarity e F1 scores

**CLI Tools** (2 file, 507 righe):
- âœ… **cli/commands.py**: Click-based CLI con 2 entry points
  - `rlcf-cli`: User commands (tasks, users, feedback, export)
  - `rlcf-admin`: Admin commands (config, db, server)

**Routers** (1 file, 485 righe):
- âœ… **routers/config_router.py**: API endpoints per dynamic configuration (GET, POST, PUT, DELETE task types)

**Services** (1 file, 122 righe):
- âœ… **services/task_service.py**: Task management business logic

**Configuration** (2 file YAML):
- âœ… **model_config.yaml** (537 bytes): Authority weights (Î±=0.3, Î²=0.5, Î³=0.2), aggregation params, AI model settings
- âœ… **task_config.yaml** (3.1 KB): 11 task types con schemas Pydantic-compatible

#### **Task Types Supportati** (11 ufficiali):

**Tier 1 - Core Pipeline**:
1. âœ… STATUTORY_RULE_QA - Interpretazione letterale
2. âœ… QA - Q&A legale generale
3. âœ… RETRIEVAL_VALIDATION - **NUOVO** (validazione KG/API/Vector agents)

**Tier 2 - Reasoning Layer**:
4. âœ… PREDICTION - Legal outcome prediction
5. âœ… NLI - Natural Language Inference
6. âœ… RISK_SPOTTING - Compliance risk identification
7. âœ… DOCTRINE_APPLICATION - Legal principle application

**Tier 3 - Preprocessing & Specialized**:
8. âœ… CLASSIFICATION - Document categorization
9. âœ… SUMMARIZATION - Document summarization
10. âœ… NER - Named Entity Recognition
11. âœ… DRAFTING - Legal document drafting

#### **Test Suite** (9 file, 2,750+ righe)

**Test Files**:
- âœ… **conftest.py** (236 righe): Async fixtures, test DB setup, model config mocks
- âœ… **test_models.py** (372 righe): SQLAlchemy models validation
- âœ… **test_authority_module.py** (230 righe): Authority scoring algorithm
- âœ… **test_aggregation_engine.py** (388 righe): Uncertainty-preserving aggregation
- âœ… **test_bias_analysis.py** (397 righe): Bias detection algorithms
- âœ… **test_export_dataset.py** (468 righe): Dataset export functionality
- âœ… **test_config_manager.py** (457 righe): **NUOVO** - ConfigManager (24 test cases)
- âœ… **test_config_router.py** (485 righe): **NUOVO** - Config API endpoints (22 test cases)
- âœ… **test_retrieval_validation_handler.py** (530 righe): **NUOVO** - RETRIEVAL_VALIDATION handler (22 test cases)

**Coverage**: 85%+ sui moduli core (target Phase 1 raggiunto)

#### **Frontend** (React 19 + TypeScript)
- âœ… Blind evaluation interface
- âœ… Analytics dashboard (authority leaderboard, system metrics)
- âœ… Configuration editor (YAML hot-reload)
- âœ… Dataset export UI (JSONL, CSV)
- âœ… Modern stack: Vite, TanStack Query, Zustand, TailwindCSS

#### **Infrastructure**
- âœ… Docker: `Dockerfile`, `docker-compose.yml`, `docker-compose.prod.yml`
- âœ… Database: SQLite (dev), PostgreSQL support (prod)
- âœ… Logging: Structured logging con file rotation (`rlcf_detailed.log`)

**Total Lines of Code (Phase 1):** ~9,885 (backend) + ~3,000 (frontend) + ~2,750 (tests) = **15,635 linee**

---

### âœ… COMPLETATO - Phase 2 Week 3 (KG Enrichment + Pipeline Integration)

**New Backend Modules** (6 file, 3,920 linee):
- âœ… `backend/preprocessing/kg_enrichment_service.py` (700 linee): Multi-source KG enrichment
- âœ… `backend/preprocessing/cypher_queries.py` (500 linee): Neo4j query builder (20+ templates)
- âœ… `backend/preprocessing/models_kg.py` (400 linee): KG data models
- âœ… `backend/preprocessing/ner_feedback_loop.py` (500 linee): NER learning loop
- âœ… `backend/preprocessing/normattiva_sync_job.py` (400 linee): Normattiva sync service
- âœ… `backend/preprocessing/contribution_processor.py` (400 linee): Community sources
- âœ… `backend/preprocessing/kg_config.yaml`: KG configuration

**New Orchestration Modules** (3 file, 1,570 linee):
- âœ… `backend/orchestration/pipeline_orchestrator.py` (720 linee): Full pipeline coordinator
- âœ… `backend/rlcf_framework/rlcf_feedback_processor.py` (520 linee): RLCF aggregation engine
- âœ… `backend/rlcf_framework/pipeline_integration.py` (330 linee): FastAPI router + endpoints

**New Test Suite** (2 file, 3,000+ linee):
- âœ… `tests/preprocessing/test_kg_complete.py` (2,156 linee): 100+ KG test cases
- âœ… `tests/integration/test_full_pipeline_integration.py` (850 linee): 50+ pipeline test cases

**New Documentation** (2 file):
- âœ… `tests/preprocessing/KG_TEST_SUMMARY.md`: Comprehensive KG test documentation
- âœ… `FULL_PIPELINE_INTEGRATION_SUMMARY.md` (28 pages): Complete integration architecture

**New API Endpoints** (5):
- `POST /pipeline/query` - Execute full legal query pipeline
- `POST /pipeline/feedback/submit` - Submit expert feedback
- `POST /pipeline/ner/correct` - Submit NER corrections
- `GET /pipeline/stats` - Pipeline performance statistics
- `GET /pipeline/health` - Component health check

**Week 3 Total:** ~9,000 linee (production + test code)

---

### âœ… COMPLETATO - Phase 2 Week 5 Day 1-2 (Document Ingestion Pipeline)

**New Backend Package** (7 file, ~2,500 linee):
- âœ… `backend/preprocessing/document_ingestion/models.py` (400 linee): 23 entity types, provenance tracking
- âœ… `backend/preprocessing/document_ingestion/document_reader.py` (350 linee): PDF/DOCX/TXT extraction
- âœ… `backend/preprocessing/document_ingestion/llm_extractor.py` (500 linee): LLM-based entity extraction
- âœ… `backend/preprocessing/document_ingestion/validator.py` (200 linee): Schema validation
- âœ… `backend/preprocessing/document_ingestion/neo4j_writer.py` (300 linee): Async Neo4j writing
- âœ… `backend/preprocessing/document_ingestion/ingestion_pipeline.py` (300 linee): Pipeline orchestration
- âœ… `backend/preprocessing/cli_ingest_document.py` (200 linee): CLI tool

**Configuration**:
- âœ… `backend/preprocessing/kg_config.yaml`: Updated with `document_ingestion` section

**Documentation** (~1,600 linee):
- âœ… `backend/preprocessing/document_ingestion/README.md` (400 linee): Comprehensive user guide
- âœ… `docs/08-iteration/DOCUMENT_INGESTION_PIPELINE_DESIGN.md` (800 linee): Design document
- âœ… `docs/08-iteration/WEEK5_DAY1-2_DOCUMENT_INGESTION.md` (400 linee): Implementation summary

**Key Features**:
- âœ… LLM-based extraction (Claude 3.5 Sonnet via OpenRouter)
- âœ… Multi-format support (PDF, DOCX, TXT)
- âœ… Complete provenance tracking (file:page:paragraph:char_range)
- âœ… All 23 MERL-T entity types supported
- âœ… Async/parallel processing (3 concurrent LLM requests)
- âœ… Cost tracking per API call
- âœ… Batch Neo4j transactions (100 nodes per batch)
- âœ… MERGE strategy to avoid duplicates
- âœ… Dry-run mode for testing

**Test Results**:
- âœ… Successfully ingested Torrente PDF (10 entities, 5 relationships)
- âœ… Duration: 69.98s for 5 segments
- âœ… Cost: $0.0448
- âœ… Data verified in Neo4j

**Week 5 Day 1-2 Total:** ~4,100 linee (production + documentation)

---

### âœ… COMPLETATO - Week 6 (Orchestration Layer - Nov 2025)

**New Orchestration Components** (18,287 linee totali):

**Day 1-2: LLM Router + Configuration** (~4,000 linee):
- âœ… `backend/orchestration/config/orchestration_config.yaml` (300 linee): Complete orchestration config
- âœ… `backend/orchestration/config/orchestration_config.py` (430 linee): Pydantic config loader
- âœ… `backend/orchestration/llm_router.py` (450 linee): 100% LLM-based Router
- âœ… `backend/orchestration/prompts/router_v1.txt` (~2,000 linee): Router prompt template
- âœ… `backend/orchestration/services/embedding_service.py` (329 linee): E5-large embeddings
- âœ… `backend/orchestration/services/qdrant_service.py` (298 linee): Qdrant collection mgmt

**Day 2: Retrieval Agents** (~3,200 linee):
- âœ… `backend/orchestration/agents/base.py` (200 linee): Abstract RetrievalAgent
- âœ… `backend/orchestration/agents/kg_agent.py` (350 linee): Neo4j KG retrieval
- âœ… `backend/orchestration/agents/api_agent.py` (450 linee): Norma Controller API
- âœ… `backend/orchestration/agents/vectordb_agent.py` (617 linee): Qdrant semantic search
- âœ… `scripts/ingest_legal_corpus.py` (419 linee): Qdrant ingestion script

**Day 3: Reasoning Experts** (~3,400 linee):
- âœ… `backend/orchestration/experts/base.py` (300 linee): Abstract Expert + ExpertContext
- âœ… `backend/orchestration/experts/literal_interpreter.py` (450 linee): Literal interpretation
- âœ… `backend/orchestration/experts/systemic_teleological.py` (500 linee): Systemic-teleological
- âœ… `backend/orchestration/experts/principles_balancer.py` (550 linee): Principles balancing
- âœ… `backend/orchestration/experts/precedent_analyst.py` (500 linee): Precedent analysis
- âœ… `backend/orchestration/experts/synthesizer.py` (1,100 linee): Opinion synthesis

**Day 4: Iteration Controller** (~1,530 linee):
- âœ… `backend/orchestration/iteration/models.py` (330 linee): Iteration state models
- âœ… `backend/orchestration/iteration/controller.py` (500 linee): Multi-turn controller with 6 stopping criteria
- âœ… `tests/orchestration/test_iteration_controller.py` (~700 linee): 25+ iteration tests

**Day 5: LangGraph Workflow + REST API** (~4,856 linee):
- âœ… `backend/orchestration/langgraph_workflow.py` (750 linee): Complete workflow (6 nodes + routing)
- âœ… `backend/orchestration/api/main.py` (343 linee): FastAPI app
- âœ… `backend/orchestration/api/schemas/` (4 files, ~1,066 linee): Query, feedback, stats, health schemas
- âœ… `backend/orchestration/api/routers/` (3 files, ~1,112 linee): Query, feedback, stats endpoints
- âœ… `backend/orchestration/api/services/` (2 files, ~840 linee): Query executor, feedback processor
- âœ… `tests/orchestration/test_api_*.py` (3 files, ~788 linee): 40+ API tests

**Test Coverage** (64+ test cases, ~1,301 linee):
- âœ… `tests/orchestration/test_llm_router.py` (500 linee, 19 tests)
- âœ… `tests/orchestration/test_embedding_service.py` (465 linee, 20+ tests)
- âœ… `tests/orchestration/test_vectordb_agent.py` (648 linee, 25+ tests)
- âœ… `tests/orchestration/test_experts.py` (expert tests)
- âœ… `tests/orchestration/test_api_query.py` (227 linee, 13 tests)
- âœ… `tests/orchestration/test_api_feedback.py` (230 linee, 13 tests)
- âœ… `tests/orchestration/test_api_stats.py` (331 linee, 14 tests)

**Key Features**:
- âœ… 100% LLM-based Router with ExecutionPlan generation
- âœ… 3 Retrieval Agents: KG (Neo4j), API (visualex), VectorDB (Qdrant)
- âœ… 4 Reasoning Experts with epistemological grounding
- âœ… Convergent/Divergent Synthesizer with uncertainty preservation
- âœ… Iteration Controller with 6 stopping criteria
- âœ… Complete LangGraph workflow with conditional routing
- âœ… 11-endpoint REST API (query execution, feedback, stats, health)
- âœ… E5-large embeddings (1024 dimensions, multilingual)
- âœ… Qdrant vector database with payload indexing

**Week 6 Total:** ~18,287 linee (implementation + tests)

---

### âœ… COMPLETATO - Week 7 (Preprocessing Integration - Nov 2025)

**Preprocessing Integration Components** (5,838 linee totali):

**Days 1-3: Interface Unification + Integration** (~688 linee):
- âœ… `backend/preprocessing/kg_enrichment_service.py` (~400 LOC modified): Unified to accept QueryUnderstandingResult
  - Changed from IntentResult to QueryUnderstandingResult
  - Updated EnrichedContext model field (intent_result â†’ query_understanding)
  - Modified all internal methods to use new interface

- âœ… `backend/orchestration/langgraph_workflow.py` (~230 LOC added): Preprocessing node integration
  - Added preprocessing_node to workflow graph
  - Changed entry point from "router" to "preprocessing"
  - Added edge preprocessing â†’ router
  - Ensured refinement loops back to router (preprocessing runs once)

- âœ… `docker-compose.yml` (~30 LOC): Infrastructure setup
  - Added postgres-orchestration service (port 5433)
  - Added Week 7 environment variables (ORCHESTRATION_DATABASE_URL, NEO4J_URI, REDIS_HOST)
  - Created postgres_orchestration_data volume
  - Added week7 profile

- âœ… `backend/orchestration/config/orchestration_config.yaml` (~28 LOC): Preprocessing configuration
  - Added preprocessing section with query_understanding and kg_enrichment settings
  - Graceful degradation flags (require_neo4j: false, require_redis: false)
  - Timeout and cache TTL configuration

**Days 4-5: Testing + Documentation** (~5,150 linee):
- âœ… `tests/orchestration/test_preprocessing_integration.py` (15 tests, ~600 LOC): Module-level tests
  - Query understanding basic flow
  - KG enrichment with unified interface
  - Preprocessing node state updates
  - Interface unification end-to-end
  - Mock preprocessing for isolated testing

- âœ… `tests/orchestration/test_workflow_with_preprocessing.py` (7 tests, ~500 LOC): End-to-end workflow tests
  - Complete workflow execution START â†’ END
  - State propagation across nodes
  - Multi-iteration with preprocessing running once
  - Error propagation and recovery
  - Performance and timing tracking

- âœ… `tests/orchestration/test_graceful_degradation.py` (11 tests, ~550 LOC): Resilience tests
  - Neo4j offline scenarios
  - Redis offline scenarios
  - Query Understanding LLM failure fallback
  - Complete and partial degradation
  - Error logging verification
  - State validity after failures

- âœ… `docs/08-iteration/WEEK7_PREPROCESSING_COMPLETE.md` (~3,500 LOC): Comprehensive documentation
  - Architecture changes (previous vs new workflow)
  - Interface unification details (problem, solution, result)
  - Implementation details with code examples
  - Testing strategy and results
  - Configuration guide
  - Deployment instructions
  - Performance metrics
  - Known limitations and future work

**Key Technical Decisions**:
- âœ… QueryUnderstandingResult chosen as single standard (more complete than IntentResult)
- âœ… Direct interface unification (no adapters - user's requirement)
- âœ… Preprocessing runs ONCE at workflow start (not in iteration loop)
- âœ… 3-level graceful degradation (Neo4j offline, Redis offline, LLM fails)
- âœ… Complete state propagation verification across all nodes

**Test Results**:
- âœ… 33 test cases across 3 files
- âœ… All tests passing with mocked external dependencies
- âœ… Interface unification successful (no adapters needed)
- âœ… Complete workflow execution verified
- âœ… Graceful degradation scenarios validated
- âœ… State validity preserved after failures

**Week 7 Total:** ~5,838 linee (implementation + tests + documentation)

---

## âŒ GAP RIMANENTI (NON Implementato)

---

### **Phase 3: Orchestration Layer** - 95% implementato âœ…
**Directory:** `backend/orchestration/` (QUASI COMPLETO - Week 6+7)

Completati in Week 6-7:
- âœ… **LLM Router** (450 LOC): 100% LLM-based decision engine with ExecutionPlan
- âœ… **KG Agent** (350 LOC): Neo4j queries with intelligent KG traversal
- âœ… **API Agent** (450 LOC): Norma Controller (visualex) integration
- âœ… **VectorDB Agent** (617 LOC): Qdrant semantic search (P1, P3, P4 patterns)
- âœ… **LangGraph Workflow** (750 LOC): Complete state machine with 6 nodes + conditional routing
- âœ… **Retrieval Agents Base** (200 LOC): Abstract agent interface
- âœ… **4 Reasoning Experts** (2,000 LOC): Literal, Systemic, Principles, Precedent
- âœ… **Synthesizer** (1,100 LOC): Convergent/Divergent synthesis with uncertainty preservation
- âœ… **Iteration Controller** (830 LOC): Multi-turn refinement with 6 stopping criteria
- âœ… **REST API** (3,318 LOC): 11 endpoints across query, feedback, stats, health
- âœ… **Preprocessing Integration** (688 LOC): Query Understanding + KG Enrichment in workflow

Rimangono (Minor):
- â³ Database persistence (currently in-memory storage) - Week 8 Days 1-2
- â³ Query Understanding LLM integration (remove mock values) - Week 8 Days 3-4
- â³ Authentication & Rate Limiting - Week 8 Day 5

**Stima completamento:** 1 settimana (Week 8)
**Status:** Orchestration layer funzionalmente completo, manca solo persistenza e rimozione mock

---

### **Phase 4: Reasoning Layer** - 100% implementato âœ…
**Directory:** `backend/orchestration/experts/` (COMPLETO - Week 6)

Completati in Week 6:
- âœ… **Literal Interpreter** (450 LOC): Positivism expert (epistemology: positivismo_giuridico)
- âœ… **Systemic-Teleological** (500 LOC): Finalism expert (epistemology: teleologia_giuridica)
- âœ… **Principles Balancer** (550 LOC): Constitutionalism expert (epistemology: costituzionalismo)
- âœ… **Precedent Analyst** (500 LOC): Empiricism expert (epistemology: giurisprudenziale)
- âœ… **Synthesizer** (1,100 LOC): Convergent/divergent modes with uncertainty preservation
- âœ… **Iteration Controller** (830 LOC): Multi-turn refinement with 6 stopping criteria
- âœ… **Expert Base** (300 LOC): Abstract Expert interface + ExpertContext data model

**Total:** ~3,230 LOC (experts + synthesizer + iteration)
**Status:** Reasoning layer completo e funzionante

---

### **Phase 5-6: Integration & Production** - 0% implementato

Mancano:
- âŒ End-to-end testing pipeline
- âŒ Performance optimization (caching, indexes)
- âŒ Security hardening (authentication, authorization)
- âŒ Kubernetes deployment manifests
- âŒ Observability stack (OpenTelemetry + SigNoz)
- âŒ CI/CD automation (GitHub Actions)
- âŒ Production monitoring & alerting

**Stima implementazione:** 12+ settimane (team 8-10 persone)

---

## âš ï¸ PROBLEMI CRITICI DA RISOLVERE SUBITO

### 1. **Dipendenze di Test Mancanti** ðŸ”´ CRITICO
**Problema:** pytest e pytest-asyncio non sono in requirements.txt
**Impatto:** Impossibile eseguire la test suite
**Fix immediato:**

```bash
# Aggiungi a requirements.txt:
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-cov>=4.1.0
httpx>=0.24.0  # Per TestClient async
```

### 2. **Environment Variables Non Documentate** ðŸŸ¡ IMPORTANTE
**Problema:** `.env.template` esiste ma mancano istruzioni chiare
**Fix immediato:** Creare `.env` con:

```bash
# Copy template
cp .env.template .env

# Variabili richieste:
OPENROUTER_API_KEY=sk-or-v1-...  # OBBLIGATORIO per AI service
ADMIN_API_KEY=secure-random-key   # OBBLIGATORIO per config API
DATABASE_URL=sqlite+aiosqlite:///./rlcf.db  # Default SQLite
```

### 3. **Package Non Installato** ðŸŸ¡ IMPORTANTE
**Problema:** Il progetto non Ã¨ installato come package
**Fix immediato:**

```bash
# Install in editable mode
pip install -e .

# Verifica CLI tools
rlcf-cli --help
rlcf-admin --help
```

---

## ðŸŽ¯ PIANO D'AZIONE OPERATIVO - PROSSIMI PASSI

### **Week 8 - Prossima Milestone Immediata** ðŸ”´

**Obiettivo:** Database persistence + Query Understanding LLM integration

**Timeline:** 5 giorni (1 settimana)
**Prerequisiti:** Week 7 completo âœ…

---

### **Week 8 Days 1-2: Database Integration** ðŸ”´ HIGH

**Obiettivo:** Replace in-memory storage with PostgreSQL + Redis persistence

**Tasks:**
1. PostgreSQL schema design (4 hours)
   - `queries` table with trace_id, session_id, query_text, status
   - `query_results` table with answer, execution_trace, metadata
   - `user_feedback` table for ratings and feedback
   - `rlcf_feedback` table for expert corrections
   - `ner_corrections` table for NER learning loop

2. Redis caching layer (4 hours)
   - Query status cache (TTL: 24h)
   - User sessions (TTL: 7d)
   - Rate limiting counters

3. Update API services (6 hours)
   - Modify `QueryExecutor` to use persistence
   - Modify `FeedbackProcessor` to save feedback
   - Update all routers to use database

**Files to Create/Modify:**
- `backend/orchestration/api/database.py` (150 LOC)
- `backend/orchestration/api/models.py` (200 LOC)
- `backend/orchestration/api/services/persistence_service.py` (300 LOC)
- `backend/orchestration/api/services/cache_service.py` (200 LOC)
- `migrations/001_create_core_tables.sql` (100 LOC)

**Estimated Time:** 14-16 hours (2 days)

---

### **Week 8 Days 3-4: Query Understanding LLM Integration** ðŸ”´ HIGH

**Obiettivo:** Remove mock values from `_build_initial_state()` and integrate real query understanding

**Current Gap:**
```python
# backend/orchestration/api/services/query_executor.py:72-96
query_context = {
    "query": request.query,
    "intent": "unknown",  # â† TODO: Replace with real intent classification
    "complexity": 0.5,    # â† TODO: Replace with real complexity score
}
```

**Tasks:**
1. Integrate `backend/preprocessing/query_understanding.py` (6 hours)
   - Import QueryUnderstandingModule
   - Call `analyze_query()` in `_preprocess_query()`
   - Update `query_context` with real values

2. KG enrichment integration (6 hours)
   - Import `KGEnrichmentService`
   - Call `enrich_context()` with QueryUnderstandingResult
   - Update `enriched_context` with real KG data

3. Testing (4 hours)
   - Update existing tests to use real preprocessing
   - Add integration tests for preprocessing flow
   - Verify state propagation to router

**Files to Modify:**
- `backend/orchestration/api/services/query_executor.py` (+180 LOC)
- `tests/orchestration/test_api_query.py` (+100 LOC)

**Estimated Time:** 16-18 hours (2 days)

---

### **Week 8 Day 5: Authentication & Rate Limiting** ðŸŸ¡ MEDIUM

**Obiettivo:** Secure API with key-based authentication and quotas

**Tasks:**
1. API key authentication (4 hours)
   - `api_keys` table with user_id, role, is_active
   - `api_usage` table for tracking
   - Middleware for API key verification

2. Rate limiting (2 hours)
   - Redis-based rate limiting
   - Quotas per user role
   - HTTP 429 responses

**Files to Create:**
- `backend/orchestration/api/middleware/auth.py` (150 LOC)
- `backend/orchestration/api/middleware/rate_limit.py` (100 LOC)
- `migrations/002_create_auth_tables.sql` (50 LOC)

**Estimated Time:** 6-8 hours (1 day)

---

### **STEP 0: Setup Ambiente (SEMPRE VALIDO - 30 minuti)** ðŸ”´

**Obiettivo:** Avere un ambiente funzionante per testing e sviluppo

```bash
# 1. Crea requirements-dev.txt per dipendenze di sviluppo
cat > requirements-dev.txt << 'EOF'
# Development & Testing Dependencies
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-cov>=4.1.0
pytest-timeout>=2.1.0
httpx>=0.24.0
black>=23.0.0
flake8>=6.0.0
mypy>=1.5.0
EOF

# 2. Installa tutte le dipendenze
pip install -r requirements.txt
pip install -r requirements-dev.txt

# 3. Installa il package in modalitÃ  editable
pip install -e .

# 4. Configura environment
cp .env.template .env
# Modifica .env con le tue API keys

# 5. Verifica installazione
rlcf-cli --version
rlcf-admin --version

# 6. Esegui test
pytest tests/rlcf/ -v --cov=backend/rlcf_framework --cov-report=html

# 7. Verifica coverage
# Apri htmlcov/index.html nel browser
```

**Output atteso:**
- âœ… Tutti i test passano (68 test cases)
- âœ… Coverage >= 85%
- âœ… CLI tools funzionanti
- âœ… Nessun import error

---

### **STEP 1: Avvio e Test Backend (1 giorno)** ðŸŸ¡

**Obiettivo:** Verificare che tutto il backend funzioni correttamente

#### A. Avvio del Backend

```bash
# 1. Inizializza database
rlcf-admin db migrate

# 2. Seed demo data (opzionale)
rlcf-admin db seed --users 5 --tasks 10

# 3. Avvia backend in modalitÃ  development
rlcf-admin server --reload

# 4. In un altro terminale, verifica API
curl http://localhost:8000/docs  # Swagger UI
curl http://localhost:8000/health  # Health check

# 5. Test manuale: crea un task via CLI
rlcf-cli tasks create --type QA --question "Test domanda legale" --context "Test"

# 6. Lista tasks
rlcf-cli tasks list --status OPEN
```

**Output atteso:**
- âœ… Server avviato su http://localhost:8000
- âœ… Swagger UI accessibile
- âœ… Task creato con successo
- âœ… Database SQLite creato in `./rlcf.db`

#### B. Test del Sistema di Configurazione Dinamica

```bash
# 1. Test hot-reload (Terminal 1)
tail -f rlcf_detailed.log | grep ConfigManager

# 2. Modifica task_config.yaml (Terminal 2)
# Aggiungi un campo a un task type esistente e salva

# 3. Verifica reload automatico nel Terminal 1
# Output: "Configuration reloaded successfully"

# 4. Test API di configurazione
curl -X GET http://localhost:8000/config/task/types

# 5. Test backup
curl -X GET http://localhost:8000/config/backups \
  -H "X-API-KEY: $ADMIN_API_KEY"
```

**Output atteso:**
- âœ… Hot-reload funziona automaticamente
- âœ… Backup creati con timestamp
- âœ… API configurazione risponde correttamente

#### C. Test RETRIEVAL_VALIDATION Handler (Nuovo Feature)

```bash
# 1. Crea task RETRIEVAL_VALIDATION via API
curl -X POST http://localhost:8000/tasks/ \
  -H "Content-Type: application/json" \
  -d '{
    "task_type": "RETRIEVAL_VALIDATION",
    "input_data": {
      "query": "Quali sono i requisiti GDPR per il consenso?",
      "retrieved_items": [
        {"id": "gdpr_art_6", "title": "GDPR Art. 6 - Base giuridica"},
        {"id": "gdpr_art_7", "title": "GDPR Art. 7 - Condizioni per il consenso"}
      ],
      "retrieval_strategy": "semantic_search",
      "agent_type": "vector_db"
    },
    "ground_truth_data": {
      "expected_items": ["gdpr_art_6", "gdpr_art_7"],
      "relevance_scores": [1.0, 1.0]
    }
  }'

# 2. Ottieni task_id dalla risposta (es. 123)
TASK_ID=123

# 3. Genera AI response
curl -X POST http://localhost:8000/tasks/$TASK_ID/generate-response

# 4. Ottieni response_id (es. 456)
RESPONSE_ID=456

# 5. Crea feedback (simula esperto)
curl -X POST http://localhost:8000/feedback/ \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": 1,
    "response_id": '$RESPONSE_ID',
    "feedback_data": {
      "relevant_items": ["gdpr_art_6", "gdpr_art_7"],
      "missing_items": [],
      "irrelevant_items": []
    },
    "accuracy_score": 5.0
  }'

# 6. Aggregazione feedback
curl -X POST http://localhost:8000/tasks/$TASK_ID/aggregate
```

**Output atteso:**
- âœ… Task RETRIEVAL_VALIDATION creato
- âœ… AI response generato
- âœ… Feedback aggregato con Jaccard similarity
- âœ… Consistency score calcolato

#### D. Regression Testing (Test Suite Completa)

```bash
# Esegui tutti i test
pytest tests/rlcf/ -v --cov=backend/rlcf_framework --cov-report=html

# Test specifici per nuove feature
pytest tests/rlcf/test_config_manager.py -v
pytest tests/rlcf/test_config_router.py -v
pytest tests/rlcf/test_retrieval_validation_handler.py -v

# Verifica coverage
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
```

**Risultati attesi:**
- âœ… 68+ test cases passano
- âœ… Coverage >= 85%
- âœ… Nessun test failure
- âœ… Nessun deprecation warning critico

---

### **STEP 2: Frontend Setup e Integrazione (1 giorno)** ðŸŸ¢

**Obiettivo:** Avere frontend + backend funzionanti insieme

```bash
# 1. Naviga nella directory frontend
cd frontend/rlcf-web

# 2. Installa dipendenze
npm install

# 3. Configura environment (crea .env.local)
cat > .env.local << 'EOF'
VITE_API_BASE_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000/ws
EOF

# 4. Avvia dev server
npm run dev

# 5. Apri browser su http://localhost:3000
# Verifica che vedi l'interfaccia RLCF

# 6. Test integrazione:
# - Crea una task dal frontend
# - Valuta una response (blind evaluation)
# - Verifica analytics dashboard
# - Testa configuration editor
```

**Output atteso:**
- âœ… Frontend su http://localhost:3000
- âœ… Backend su http://localhost:8000
- âœ… API calls funzionano (verifica nel Network tab del browser)
- âœ… Nessun CORS error

---

### **STEP 3: Docker Deployment Locale (1 giorno)** ðŸŸ¢

**Obiettivo:** Testare deployment con Docker Compose

```bash
# 1. Build immagini Docker
docker-compose build

# 2. Avvia stack completo
docker-compose up -d

# 3. Verifica container attivi
docker-compose ps

# 4. Verifica logs
docker-compose logs -f backend
docker-compose logs -f frontend

# 5. Test endpoints
curl http://localhost:8000/docs
curl http://localhost:3000

# 6. Esegui test dentro container
docker-compose exec backend pytest tests/rlcf/ -v

# 7. Ferma stack
docker-compose down
```

**Output atteso:**
- âœ… Tutti i container running
- âœ… Backend risponde su porta 8000
- âœ… Frontend risponde su porta 3000
- âœ… Database PostgreSQL funzionante (se configurato)

---

### **STEP 4: Documentazione & Knowledge Transfer (2 giorni)** ðŸŸ¢

**Obiettivo:** Documentare tutto per futuri sviluppatori

#### A. README Updates

Aggiornare README principale con:
- Setup rapido (Quick Start testato e funzionante)
- Architettura aggiornata (cosa c'Ã¨ vs cosa manca)
- Deployment instructions (Docker + native)

#### B. API Documentation

```bash
# 1. Genera OpenAPI schema
curl http://localhost:8000/openapi.json > docs/api-schema.json

# 2. Valida schema
npm install -g @apidevtools/swagger-cli
swagger-cli validate docs/api-schema.json

# 3. Genera Postman collection
# Importa openapi.json in Postman e salva collection
```

#### C. Video Tutorial (opzionale ma consigliato)

Registrare screencast che mostra:
1. Setup ambiente da zero (15 min)
2. Creazione task e feedback workflow (10 min)
3. Dynamic configuration in azione (5 min)
4. Export dataset per fine-tuning (5 min)

#### D. Troubleshooting Guide

Aggiornare `docs/02-methodology/rlcf/reference/troubleshooting.md` con:
- Problemi comuni di setup
- Errori database piÃ¹ frequenti
- Problemi CORS frontend-backend
- Performance tuning tips

---

## ðŸš€ PHASE 2: PREPROCESSING LAYER - Piano Dettagliato

**Timeline:** 6 settimane (1-2 developers)
**Prerequisito:** Phase 1 completamente testata e deployment-ready
**Budget stimato:** â‚¬24,000 - â‚¬36,000 (1-2 dev Ã— 6 settimane Ã— â‚¬4,000/settimana)

---

### **Settimana 1-2: Knowledge Graph Setup**

**Obiettivo:** Avere Memgraph funzionante con schema legale italiano

#### Task Specifici:

```bash
# 1. Setup Memgraph in Docker
cat > docker-compose.memgraph.yml << 'EOF'
version: '3'
services:
  memgraph:
    image: memgraph/memgraph:latest
    ports:
      - "7687:7687"  # Bolt protocol
      - "7444:7444"  # Lab interface
    volumes:
      - ./data/memgraph:/var/lib/memgraph
    environment:
      - MEMGRAPH_LOG_LEVEL=INFO
EOF

docker-compose -f docker-compose.memgraph.yml up -d

# 2. Crea schema legale italiano
# File: infrastructure/memgraph/schema.cypher
```

**Schema Design** (Cypher):

```cypher
// Nodi principali
CREATE CONSTRAINT ON (n:Norma) ASSERT n.id IS UNIQUE;
CREATE CONSTRAINT ON (a:Articolo) ASSERT a.id IS UNIQUE;
CREATE CONSTRAINT ON (c:Concetto) ASSERT c.id IS UNIQUE;

// Indici per performance
CREATE INDEX ON :Norma(tipo);  // "legge", "decreto", "regolamento"
CREATE INDEX ON :Articolo(numero);
CREATE INDEX ON :Concetto(dominio);  // "gdpr", "contratti", etc.

// Relazioni
// (:Norma)-[:CONTIENE]->(:Articolo)
// (:Articolo)-[:TRATTA]->(:Concetto)
// (:Articolo)-[:MODIFICA]->(:Articolo)
// (:Articolo)-[:ABROGATO_DA]->(:Articolo)
```

**Deliverables Settimana 1-2:**
- âœ… Memgraph running e accessibile
- âœ… Schema design documentato
- âœ… Script di ingestion per prime 100 norme (test)
- âœ… Cypher queries di base testate

---

### **Settimana 3-4: Query Understanding Module**

**Obiettivo:** NER + Intent Classification per query legali italiane

#### Implementazione:

```python
# File: backend/preprocessing/query_understanding.py

from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModelForSequenceClassification
from typing import List, Dict, Any
import spacy

class LegalQueryUnderstanding:
    """
    Analizza query legali in italiano estraendo:
    - Named entities (riferimenti normativi, date, importi)
    - Intent (ricerca normativa, interpretazione, drafting)
    - Concetti legali menzionati
    """

    def __init__(self):
        # NER: italian-legal-bert
        self.tokenizer = AutoTokenizer.from_pretrained("dlicari/Italian-Legal-BERT")
        self.ner_model = AutoModelForTokenClassification.from_pretrained("dlicari/Italian-Legal-BERT")

        # Intent classification
        self.intent_model = AutoModelForSequenceClassification.from_pretrained("dbmdz/bert-base-italian-xxl-cased")

        # spaCy per dependency parsing
        self.nlp = spacy.load("it_core_news_lg")

    async def analyze_query(self, query_text: str) -> Dict[str, Any]:
        """
        Analizza una query legale e ritorna:
        {
            "entities": [...],  # NER results
            "intent": "...",    # SEARCH, INTERPRETATION, COMPLIANCE_CHECK
            "concepts": [...],  # Concetti legali identificati
            "norm_references": [...]  # Riferimenti normativi estratti
        }
        """
        # Implementazione NER
        entities = self._extract_entities(query_text)

        # Intent classification
        intent = self._classify_intent(query_text)

        # Concept extraction
        concepts = self._extract_legal_concepts(query_text)

        # Norm reference extraction (regex + NER)
        norm_refs = self._extract_norm_references(query_text)

        return {
            "entities": entities,
            "intent": intent,
            "concepts": concepts,
            "norm_references": norm_refs
        }
```

**Dataset per Training/Fine-tuning:**
- Italian-Legal-BERT giÃ  pre-trained su corpus giuridico italiano
- Fine-tune su dataset RLCF (usa feedback esistente come labels)
- Annotare 200-300 query per intent classification

**Deliverables Settimana 3-4:**
- âœ… `backend/preprocessing/query_understanding.py` implementato
- âœ… NER funzionante per entitÃ  legali italiane
- âœ… Intent classifier con 85%+ accuracy
- âœ… Test suite per query understanding

---

### **Settimana 5-6: KG Enrichment Service**

**Obiettivo:** Espandere query con informazioni dal KG

#### Implementazione:

```python
# File: backend/preprocessing/kg_enrichment.py

from neo4j import AsyncGraphDatabase
from typing import List, Dict, Any

class KnowledgeGraphEnrichment:
    """
    Arricchisce query context interrogando Memgraph
    """

    def __init__(self, uri="bolt://localhost:7687"):
        self.driver = AsyncGraphDatabase.driver(uri)

    async def enrich_context(self, query_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Input: Output di QueryUnderstanding
        Output: Enriched context con norme, articoli, concetti correlati
        """
        concepts = query_analysis["concepts"]
        norm_refs = query_analysis["norm_references"]

        # Query 1: Espandi concetti â†’ norme correlate
        related_norms = await self._expand_concepts_to_norms(concepts)

        # Query 2: Recupera full text articoli citati
        article_texts = await self._fetch_article_texts(norm_refs)

        # Query 3: Trova norme correlate (MODIFICA, ABROGATO_DA)
        related_legislation = await self._find_related_legislation(norm_refs)

        return {
            "original_query": query_analysis,
            "related_norms": related_norms,
            "article_texts": article_texts,
            "related_legislation": related_legislation,
            "kg_confidence": 0.85  # Quanto ci fidiamo del KG
        }

    async def _expand_concepts_to_norms(self, concepts: List[str]) -> List[Dict]:
        """
        Cypher query: MATCH (c:Concetto)-[:TRATTA]-(a:Articolo)-[:CONTIENE]-(n:Norma)
                      WHERE c.nome IN $concepts
                      RETURN n, a LIMIT 10
        """
        async with self.driver.session() as session:
            query = """
                MATCH (c:Concetto)<-[:TRATTA]-(a:Articolo)<-[:CONTIENE]-(n:Norma)
                WHERE c.nome IN $concepts
                RETURN n.id as norm_id, n.titolo as title,
                       collect(a.numero) as articles,
                       n.anno as year
                ORDER BY n.anno DESC
                LIMIT 10
            """
            result = await session.run(query, concepts=concepts)
            return [record.data() async for record in result]
```

**Cypher Queries Principali:**

```cypher
// 1. Espansione concetti â†’ norme
MATCH (c:Concetto)<-[:TRATTA]-(a:Articolo)<-[:CONTIENE]-(n:Norma)
WHERE c.nome IN ['consenso', 'gdpr', 'privacy']
RETURN n, a
LIMIT 10;

// 2. Trova norme correlate
MATCH (a1:Articolo)-[:MODIFICA|ABROGATO_DA*1..3]-(a2:Articolo)
WHERE a1.id = 'cc_art_1321'  // Codice civile art. 1321
RETURN a2, path;

// 3. Temporal queries (norme vigenti)
MATCH (n:Norma)
WHERE n.data_entrata_vigore <= date()
  AND (n.data_abrogazione IS NULL OR n.data_abrogazione > date())
RETURN n;
```

**Deliverables Settimana 5-6:**
- âœ… `backend/preprocessing/kg_enrichment.py` implementato
- âœ… Integration con Memgraph funzionante
- âœ… 10+ Cypher queries ottimizzate
- âœ… Performance < 300ms per enrichment
- âœ… Test suite con mock KG

---

### **Infrastruttura & Data**

#### Data Ingestion Pipeline:

```bash
# Script: scripts/ingest_legal_data.py

# 1. Scarica norme da Normattiva.it API
# 2. Parse XML Akoma Ntoso
# 3. Extract articoli, commi, riferimenti
# 4. Populate Memgraph con batch inserts
# 5. Create indexes and constraints

# Esecuzione:
python scripts/ingest_legal_data.py \
  --source normattiva \
  --start-year 2000 \
  --norm-types legge,decreto \
  --batch-size 100
```

#### Fonti Dati Consigliate:
1. **Normattiva.it** - Testi normativi ufficiali (Akoma Ntoso XML)
2. **EUR-Lex** - Legislazione europea
3. **Corte Costituzionale** - Sentenze e giurisprudenza
4. **Dataset GDPR** - Regolamento e linee guida

**Stima norme da ingerire (Phase 2):**
- Codice Civile: ~2,969 articoli
- Codice Penale: ~734 articoli
- GDPR: 99 articoli + considerando
- Costituzione: 139 articoli
- Top 50 leggi rilevanti (es. Legge Fallimentare, Statuto Lavoratori)
**Totale: ~5,000 articoli** (baseline per test)

---

### **Testing Strategy Phase 2**

```python
# tests/preprocessing/test_query_understanding.py
@pytest.mark.asyncio
async def test_ner_extracts_norm_references():
    qu = LegalQueryUnderstanding()
    result = await qu.analyze_query("L'art. 1321 c.c. definisce il contratto")
    assert "cc_art_1321" in result["norm_references"]

# tests/preprocessing/test_kg_enrichment.py
@pytest.mark.asyncio
async def test_concept_expansion():
    kg = KnowledgeGraphEnrichment()
    result = await kg.enrich_context({"concepts": ["contratto"]})
    assert len(result["related_norms"]) > 0
    assert any("1321" in str(norm) for norm in result["related_norms"])
```

**Coverage target:** 80%+ su preprocessing layer

---

### **Deliverables Finali Phase 2:**

- âœ… Memgraph con 5,000+ articoli ingested
- âœ… Query Understanding con NER + Intent (85%+ accuracy)
- âœ… KG Enrichment con <300ms latency
- âœ… 3 nuovi moduli Python (query_understanding, kg_enrichment, kg_service)
- âœ… 50+ test cases per preprocessing
- âœ… Documentazione API per preprocessing layer
- âœ… Performance benchmarks documentati

**Metriche di Successo:**
- Entity extraction F1 score > 0.85
- Intent classification accuracy > 0.85
- KG query latency < 300ms (p95)
- Enrichment recall > 0.80 (trova almeno 80% norme rilevanti)

---

## ðŸ“‹ CHECKLIST PRIMA DI INIZIARE PHASE 2

**Assicurati che Phase 1 sia production-ready:**

- [ ] Tutti i 68+ test passano senza errori
- [ ] Coverage >= 85% verificato con report HTML
- [ ] Backend avviabile con `rlcf-admin server --reload`
- [ ] Frontend avviabile con `npm run dev`
- [ ] Docker Compose funzionante (backend + frontend)
- [ ] Environment variables documentate e validate
- [ ] API documentation (Swagger) accessibile e completa
- [ ] CLI tools (`rlcf-cli`, `rlcf-admin`) funzionanti
- [ ] Nessun warning critico nei log
- [ ] Performance baseline documentata (latency endpoints, memoria)
- [ ] Git repository pulito (no file temporanei, .env ignored)
- [ ] README aggiornato con setup istructions testate

**Team & Skills Requirements Phase 2:**

- [ ] 1-2 Python developers (senior level)
- [ ] Competenze: Graph databases (Cypher), NLP, transformers
- [ ] Accesso a Normattiva.it o dataset legale italiano
- [ ] Budget: â‚¬24k-â‚¬36k (6 settimane)
- [ ] Hardware: GPU per BERT models (almeno 8GB VRAM) o Colab/SageMaker

---

## ðŸ’¡ RACCOMANDAZIONI TECNICHE CRITICHE

### 1. **Non Partire da Zero su Phase 2-6**

**Usa TECHNOLOGY_RECOMMENDATIONS.md** come bibbia:
- LangGraph (non LangChain) per orchestration
- Memgraph (non Neo4j) per graph - **10-25x piÃ¹ veloce!**
- Qdrant (non Weaviate/Chroma) per vectors - 30-40ms latency
- Voyage Multilingual 2 per embeddings italiano

### 2. **Vertical Slice, Non Horizontal**

**âŒ SBAGLIATO:**
```
Settimana 1-4: Tutto il KG
Settimana 5-8: Tutti gli agents
Settimana 9-12: Tutti gli experts
```

**âœ… CORRETTO:**
```
Settimana 1-2: KG + 1 query end-to-end
Settimana 3-4: NER + KG enrichment testato
Settimana 5-6: Integration con RLCF
```

Ogni 2 settimane hai qualcosa di FUNZIONANTE e DIMOSTRABILE.

### 3. **RLCF Fin dall'Inizio**

Phase 2-6 non sono separate da RLCF. RLCF deve validare tutto:

- **Preprocessing**: RETRIEVAL_VALIDATION per query understanding quality
- **Orchestration**: RETRIEVAL_VALIDATION per agent retrieval quality
- **Reasoning**: QA, STATUTORY_RULE_QA per expert outputs

**Pattern:**
1. Implementa feature (es. KG Agent)
2. Crea task RETRIEVAL_VALIDATION per testarlo
3. Raccogli feedback esperti legali
4. Usa aggregation RLCF per migliorare
5. Itera (Build-Measure-Learn)

### 4. **Testing = 30% del Tempo**

Non "prima sviluppo, poi testo". **TDD** (Test-Driven Development):

```python
# 1. Scrivi il test PRIMA
def test_kg_enrichment_finds_contratti():
    result = kg.enrich_context({"concepts": ["contratto"]})
    assert "cc_art_1321" in result["norm_ids"]

# 2. Implementa finchÃ© il test passa
# 3. Refactoring
# 4. Repeat
```

**Percentuale tempo:**
- 40% implementation
- 30% testing
- 20% documentation
- 10% debugging/optimization

### 5. **Evita Over-Engineering**

**Fase 2 = MVP del Preprocessing**, non il sistema finale perfetto.

- KG con 5,000 articoli Ã¨ sufficiente (non servono 100,000)
- NER con 85% accuracy Ã¨ OK (non serve 99%)
- Intent classification a 5 classi (non 50)

**Regola: "Funzionante e testato" > "Perfetto e mai finito"**

---

## ðŸŽ¯ METRICHE DI SUCCESSO GLOBALI

### Phase 1 (Completata) âœ…
- [x] 15,635 linee di codice funzionante
- [x] 68+ test cases passano
- [x] 85%+ coverage
- [x] 11 task types supportati
- [x] CLI tools funzionanti
- [x] Docker deployment ready

### Phase 2 (Target - 6 settimane)
- [ ] Memgraph con 5,000+ articoli
- [ ] NER F1 score > 0.85
- [ ] KG query < 300ms (p95)
- [ ] 50+ test cases preprocessing
- [ ] End-to-end query â†’ enriched context

### Phase 3 (Target - 8 settimane)
- [ ] LLM Router con LangGraph
- [ ] 3 retrieval agents (KG, API, Vector)
- [ ] Routing decision < 500ms
- [ ] Agent execution < 2s (parallel)
- [ ] 100+ test cases orchestration

### Phase 4 (Target - 10 settimane)
- [ ] 4 expert types implementati
- [ ] Synthesizer (convergent + divergent)
- [ ] Expert reasoning < 8s
- [ ] RLCF integration per expert feedback
- [ ] 150+ test cases reasoning

### Phase 5-6 (Target - 12 settimane)
- [ ] End-to-end latency < 11s
- [ ] Kubernetes deployment
- [ ] Observability (SigNoz)
- [ ] CI/CD pipeline
- [ ] Production monitoring

---

## ðŸ”— RISORSE UTILI

### Documentazione Tecnica
- [IMPLEMENTATION_ROADMAP.md](../../IMPLEMENTATION_ROADMAP.md) - Piano completo 42 settimane
- [TECHNOLOGY_RECOMMENDATIONS.md](../../TECHNOLOGY_RECOMMENDATIONS.md) - Tech stack 2025
- [RLCF.md](../../02-methodology/rlcf/RLCF.md) - Core paper con formule

### Codice di Riferimento
- `backend/rlcf_framework/` - Phase 1 implementation (studiala!)
- `tests/rlcf/` - Test patterns e fixtures
- `backend/rlcf_framework/task_handlers/` - Strategy pattern per nuovi handlers

### External Resources
- **Memgraph Docs**: https://memgraph.com/docs
- **Italian-Legal-BERT**: https://huggingface.co/dlicari/Italian-Legal-BERT
- **LangGraph Tutorial**: https://langchain-ai.github.io/langgraph/
- **Normattiva API**: https://www.normattiva.it/
- **Akoma Ntoso Standard**: http://www.akomantoso.org/

---

## âš ï¸ RISCHI E MITIGAZIONI

### Rischio 1: Dataset Legale Italiano Insufficiente
**ProbabilitÃ :** ALTA ðŸ”´
**Impatto:** ALTO (senza dati, no KG)
**Mitigazione:**
- Start con fonti pubbliche (Normattiva.it, EUR-Lex)
- Partnership con universitÃ  di giurisprudenza
- Annotazione manuale iniziale (200-300 esempi)
- Uso di data augmentation

### Rischio 2: Performance KG Queries
**ProbabilitÃ :** MEDIA ðŸŸ¡
**Impatto:** MEDIO (latency > 300ms)
**Mitigazione:**
- Memgraph invece di Neo4j (10-25x faster)
- Indexing aggressivo su nodi chiave
- Query caching con Redis
- Benchmark continuo durante sviluppo

### Rischio 3: ComplessitÃ  LLM Router
**ProbabilitÃ :** ALTA ðŸ”´
**Impatto:** ALTO (blocca Phase 3-4)
**Mitigazione:**
- Start con rule-based router semplice (Phase 2)
- Migrazione graduale a LLM-based (Phase 3)
- Strangler Fig pattern
- Extensive testing con RETRIEVAL_VALIDATION

### Rischio 4: Team Turnover
**ProbabilitÃ :** MEDIA ðŸŸ¡
**Impatto:** CRITICO (knowledge loss)
**Mitigazione:**
- Documentazione ossessiva (questo doc!)
- Pair programming
- Code review mandatory
- Video knowledge transfer

---

## ðŸ“ž SUPPORTO & CONTRIBUTI

**Per domande tecniche:**
- Consulta prima la documentazione in `docs/`
- Apri issue su GitHub con tag appropriato
- Esegui SEMPRE i test prima di PR

**Per contribuire:**
1. Fork repository
2. Crea feature branch (`git checkout -b feature/phase2-kg-setup`)
3. Implementa con TDD (test first!)
4. Commit conventionali (`feat:`, `fix:`, `docs:`, `test:`)
5. PR con descrizione dettagliata

---

## ðŸŽ“ CONCLUSIONI E PROSSIMO STEP OPERATIVO

### Situazione Attuale (2025-11-06)

**âœ… COMPLETATO - Phase 1:**
- 15,635 linee di codice production-ready
- Backend FastAPI con 50+ endpoints
- Frontend React 19 con UI completa
- 68+ test cases con 85%+ coverage
- 11 task types RLCF funzionanti
- CLI tools e Docker deployment

**âœ… COMPLETATO - Week 3 (KG + Pipeline):**
- 9,000 linee di codice
- Multi-source KG enrichment (5 sources)
- Full pipeline orchestration
- RLCF feedback integration
- 100+ test cases

**âœ… COMPLETATO - Week 5 Day 1-2 (Document Ingestion):**
- 4,100 linee di codice
- LLM-based entity extraction
- Neo4j batch writing
- Multi-format support (PDF, DOCX, TXT)

**âœ… COMPLETATO - Week 6 (Orchestration Layer):**
- 18,287 linee di codice
- 100% LLM-based Router
- 3 Retrieval Agents (KG, API, VectorDB)
- 4 Reasoning Experts + Synthesizer
- Iteration Controller
- Complete LangGraph workflow
- 11-endpoint REST API

**âœ… COMPLETATO - Week 7 (Preprocessing Integration):**
- 5,838 linee di codice
- Interface unification (QueryUnderstandingResult standard)
- Preprocessing node integrated into workflow
- 33 comprehensive test cases
- Graceful degradation at 3 levels

**ðŸ“ DOVE SIAMO:**
- **Phase 1**: COMPLETO âœ… (RLCF Core)
- **Phase 2**: 60% completo (KG + Pipeline + Document Ingestion)
- **Phase 3**: 95% completo âœ… (Orchestration Layer - manca solo persistenza)
- **Phase 4**: 100% completo âœ… (Reasoning Layer)
- **Total LOC**: ~52,860 linee

**FunzionalitÃ  Disponibili:**
- âœ… Authority scoring con formula matematica
- âœ… Aggregation uncertainty-preserving (Shannon entropy)
- âœ… Bias detection (3 types)
- âœ… Dynamic configuration
- âœ… Multi-source KG enrichment
- âœ… LLM Router con ExecutionPlan
- âœ… 3 Retrieval Agents (KG, API, Vector)
- âœ… 4 Reasoning Experts
- âœ… Convergent/Divergent Synthesizer
- âœ… Iteration Controller (6 stopping criteria)
- âœ… Complete LangGraph workflow (7 nodes)
- âœ… REST API (11 endpoints)
- âœ… Preprocessing integration

**âŒ COSA MANCA (Minor):**
- Database persistence (PostgreSQL + Redis) - Week 8 Days 1-2
- Query Understanding LLM integration (remove mocks) - Week 8 Days 3-4
- Authentication & Rate Limiting - Week 8 Day 5
- Admin interface - Week 9
- Frontend integration - Week 10
- Production deployment - Week 11-15

---

### **AZIONE IMMEDIATA - NEXT 7 DAYS (Week 8)**

#### **Giorno 1-2: Database Integration** ðŸ”´ CRITICO

**Obiettivo:** Sostituire in-memory storage con PostgreSQL + Redis

```bash
# 1. Setup PostgreSQL orchestration database
docker-compose --profile week7 up -d postgres-orchestration redis

# 2. Create migration files
mkdir -p migrations
cat > migrations/001_create_core_tables.sql << 'EOF'
-- Queries table
CREATE TABLE queries (...);
-- Query results table
CREATE TABLE query_results (...);
-- User feedback table
CREATE TABLE user_feedback (...);
-- RLCF feedback table
CREATE TABLE rlcf_feedback (...);
-- NER corrections table
CREATE TABLE ner_corrections (...);
EOF

# 3. Run migrations
psql $ORCHESTRATION_DATABASE_URL -f migrations/001_create_core_tables.sql

# 4. Create persistence layer
# File: backend/orchestration/api/database.py (SQLAlchemy models)
# File: backend/orchestration/api/services/persistence_service.py (CRUD)
# File: backend/orchestration/api/services/cache_service.py (Redis)

# 5. Update QueryExecutor to use persistence
# Modify: backend/orchestration/api/services/query_executor.py
```

**Deliverables:**
- âœ… PostgreSQL schema migrated
- âœ… Redis caching functional
- âœ… QueryExecutor saving to DB
- âœ… Feedback endpoints persisting data

---

#### **Giorno 3-4: Query Understanding LLM Integration** ðŸ”´ CRITICO

**Obiettivo:** Rimuovere mock values e integrare preprocessing reale

```bash
# 1. Update query_executor.py
# Remove mock values at lines 72-96
# Add real preprocessing integration

# 2. Import preprocessing modules
from backend.preprocessing.query_understanding import analyze_query
from backend.preprocessing.kg_enrichment_service import KGEnrichmentService

# 3. Call real preprocessing in _build_initial_state()
preprocessing_result = await analyze_query(request.query, query_id=trace_id)
enriched = await kg_service.enrich_context(preprocessing_result)

# 4. Update tests to use real preprocessing
# Modify: tests/orchestration/test_api_query.py
```

**Deliverables:**
- âœ… Mock values removed
- âœ… Real intent classification integrated
- âœ… Real KG enrichment integrated
- âœ… Tests passing with real preprocessing

---

#### **Giorno 5: Authentication & Rate Limiting** ðŸŸ¡ IMPORTANTE

**Obiettivo:** Secure API for production readiness

```bash
# 1. Create auth tables migration
cat > migrations/002_create_auth_tables.sql << 'EOF'
CREATE TABLE api_keys (...);
CREATE TABLE api_usage (...);
EOF

# 2. Implement auth middleware
# File: backend/orchestration/api/middleware/auth.py
# File: backend/orchestration/api/middleware/rate_limit.py

# 3. Apply middleware to FastAPI app
# Modify: backend/orchestration/api/main.py

# 4. Test authenticated endpoints
curl -H "X-API-Key: test-key-123" http://localhost:8000/query/execute
```

**Deliverables:**
- âœ… API key authentication working
- âœ… Rate limiting functional
- âœ… Usage tracking in database

---

**Prossima Milestone:** Week 8 completato - Sistema production-ready con persistenza
**Target Date:** 2025-11-13 (7 giorni da oggi)
**Owner:** Development Team

---

*Documento aggiornato il 2025-11-06 dopo completamento Week 7 (Preprocessing Integration)*
*Prossimo aggiornamento: Post-Week 8 completion (2025-11-13)*

---

### Phase 3: Orchestration Layer (COMPLETO âœ… - Week 6)

**Obiettivo:** LLM Router + Retrieval Agents

#### Componenti Implementati:

1. **LLM Router** âœ…
   - 100% LLM-based decision engine (`backend/orchestration/llm_router.py` - 450 LOC)
   - ExecutionPlan generation con Claude 3.5 Sonnet
   - Dynamic routing con fallback strategy
   - LangGraph state machine integration

2. **Retrieval Agents** âœ…
   - **KG Agent** âœ… (`backend/orchestration/agents/kg_agent.py` - 350 LOC): Neo4j queries
   - **API Agent** âœ… (`backend/orchestration/agents/api_agent.py` - 450 LOC): visualex integration
   - **VectorDB Agent** âœ… (`backend/orchestration/agents/vectordb_agent.py` - 617 LOC): Qdrant semantic search

3. **RLCF Integration for Agents** âœ…
   - RETRIEVAL_VALIDATION task handler ready (Phase 1)
   - Feedback endpoints implemented (`/feedback/rlcf`)
   - Authority weighting for retrieval quality

**Deliverables Completati:**
- âœ… `backend/orchestration/llm_router.py` (450 LOC)
- âœ… `backend/orchestration/agents/` (kg, api, vector - 1,417 LOC)
- âœ… LangGraph workflow with 7 nodes (750 LOC)
- âœ… Retrieval strategy configs in orchestration_config.yaml

**Completato:** Week 6 (5 giorni)

---

### Phase 4: Reasoning Layer (COMPLETO âœ… - Week 6)

**Obiettivo:** 4 Expert Types + Synthesizer

#### Componenti Implementati:

1. **4 Expert Types** âœ…
   - **Literal Interpreter** âœ… (450 LOC): Positivism expert (epistemology: positivismo_giuridico)
   - **Systemic-Teleological** âœ… (500 LOC): Finalism expert (epistemology: teleologia_giuridica)
   - **Principles Balancer** âœ… (550 LOC): Constitutionalism expert (epistemology: costituzionalismo)
   - **Precedent Analyst** âœ… (500 LOC): Empiricism expert (epistemology: giurisprudenziale)

2. **Synthesizer** âœ…
   - **Convergent mode** âœ…: Consensus extraction con weighted voting
   - **Divergent mode** âœ…: Preserve multiple perspectives
   - **Uncertainty quantification** âœ…: Shannon entropy + consensus metrics
   - Total: 1,100 LOC

3. **Iteration Controller** âœ…
   - Multi-turn refinement (830 LOC)
   - 6 stopping criteria con priority evaluation
   - Improvement delta calculation
   - Convergence detection

4. **RLCF Integration for Experts** âœ…
   - QA, STATUTORY_RULE_QA task handlers ready (Phase 1)
   - Expert-specific metadata in API responses
   - Authority scoring per expert type planned (Week 9)

**Deliverables Completati:**
- âœ… `backend/orchestration/experts/` (4 expert modules - 2,000 LOC)
- âœ… `backend/orchestration/experts/synthesizer.py` (1,100 LOC)
- âœ… `backend/orchestration/iteration/controller.py` (830 LOC)
- âœ… Prompt templates embedded in expert classes
- âœ… RLCF feedback endpoints ready

**Completato:** Week 6 Day 3-4 (2 giorni)

---

## ðŸ”§ Miglioramenti Tecnici Consigliati

### Immediate (1-2 settimane)

1. **ConfigManager Enhancements**
   - [ ] Add webhook support for config changes (notify external systems)
   - [ ] Add diff viewer for comparing configs
   - [ ] Add validation dry-run endpoint

2. **RETRIEVAL_VALIDATION Improvements**
   - [ ] Add relevance scoring (0.0-1.0)
   - [ ] Add explanation field (why relevant/irrelevant)
   - [ ] Add missing_items ranking

3. **Monitoring Dashboard**
   - [ ] Grafana dashboard for config changes
   - [ ] Backup retention visualization
   - [ ] Hot-reload success/failure metrics

### Short-Term (1 mese)

1. **UI Admin Panel**
   - Visual task type editor
   - Schema builder (drag & drop)
   - Backup browser with diff
   - Config validation preview

2. **Multi-Environment Support**
   - Development/staging/production configs
   - Environment promotion workflow
   - Config sync between environments

3. **Schema Migration System**
   - Automatic migration of existing tasks to new schemas
   - Backward compatibility layer
   - Rollback support

---

## ðŸ“ˆ Metriche di Successo

### Phase 1 (Current)
- âœ… 11 task types implementati
- âœ… 85%+ test coverage
- âœ… Hot-reload funzionante
- âœ… Zero downtime config changes

### Phase 2 (Target)
- [ ] Query Understanding accuracy > 90%
- [ ] KG with 10,000+ legal norms
- [ ] Entity linking precision > 85%

### Phase 3 (Target)
- [ ] LLM Router decision latency < 500ms
- [ ] Retrieval agent response time < 2s
- [ ] RETRIEVAL_VALIDATION feedback rate > 60%

### Phase 4 (Target)
- [ ] Expert reasoning quality > 80% (RLCF scored)
- [ ] Synthesis latency < 3s
- [ ] User satisfaction > 4/5

---

## ðŸ’¡ Raccomandazioni Architetturali

### 1. Event-Driven Architecture

Considera di usare **events** per comunicazione tra layer:

```python
# Event bus per layer communication
from dataclasses import dataclass

@dataclass
class QueryProcessedEvent:
    query_id: str
    entities: List[Entity]
    intent: str

@dataclass
class RetrievalCompletedEvent:
    query_id: str
    results: List[RetrievalResult]
    agent_type: str

# Pub/sub per RLCF feedback loops
```

### 2. Caching Strategy

Implementare caching multi-livello:

```python
# L1: In-memory (ConfigManager giÃ  lo fa)
# L2: Redis per query/retrieval results
# L3: CDN per static assets

# TTL strategy per diverse cache keys
```

### 3. Observability

Setup completo di observability:

```python
# Logs: Structured logging (JSON)
# Metrics: Prometheus + Grafana
# Traces: OpenTelemetry
# Profiles: py-spy per profiling
```

---

## ðŸŽ“ Formazione Team

### Per Phase 2 Setup

**Skills needed:**
- Graph databases (Cypher, Memgraph)
- NLP in italiano (spaCy, transformers)
- Knowledge representation

**Resources:**
- Memgraph docs: https://memgraph.com/docs
- spaCy Italian: https://spacy.io/models/it
- italian-legal-bert: Hugging Face

### Per Phase 3 Setup

**Skills needed:**
- LangGraph / LangChain
- Async programming
- API integration

**Resources:**
- LangGraph tutorial: https://langchain-ai.github.io/langgraph/
- FastAPI advanced: https://fastapi.tiangolo.com/advanced/

---

## ðŸ“‹ Checklist Immediata

### Prima di Procedere a Phase 2

- [ ] Testare sistema configurazione dinamica completamente
- [ ] Verificare hot-reload in ambiente Docker
- [ ] Documentare tutti gli endpoint API (Swagger)
- [ ] Creare video tutorial per ConfigManager
- [ ] Setup monitoring/alerting base
- [ ] Backup strategy per configurazioni in produzione
- [ ] Code review del sistema RETRIEVAL_VALIDATION
- [ ] Performance testing (load test con 100+ concurrent requests)
- [ ] Security audit (API key management, validation)

### Decisioni da Prendere

1. **Database per produzione:**
   - [ ] PostgreSQL on-premise vs managed (RDS, Supabase)
   - [ ] Memgraph self-hosted vs managed

2. **Deployment strategy:**
   - [ ] Docker Compose vs Kubernetes
   - [ ] CI/CD pipeline (GitHub Actions, GitLab CI)

3. **Team structure:**
   - [ ] Quanti developer full-time?
   - [ ] Legal expert involvement frequency?
   - [ ] Budget per infrastruttura cloud?

---

## ðŸ”— Link Utili

**Documentazione Tecnica:**
- [DYNAMIC_CONFIGURATION.md](../04-implementation/DYNAMIC_CONFIGURATION.md)
- [IMPLEMENTATION_ROADMAP.md](../../IMPLEMENTATION_ROADMAP.md)
- [TECHNOLOGY_RECOMMENDATIONS.md](../../TECHNOLOGY_RECOMMENDATIONS.md)

**Codice:**
- ConfigManager: `backend/rlcf_framework/config_manager.py`
- Config Router: `backend/rlcf_framework/routers/config_router.py`
- RETRIEVAL_VALIDATION: `backend/rlcf_framework/task_handlers/retrieval_validation_handler.py`

**Testing:**
- Test script: `scripts/test_dynamic_config.sh`
- Quick start: [DYNAMIC_CONFIG_QUICKSTART.md](DYNAMIC_CONFIG_QUICKSTART.md)

---

## ðŸ“ž Support & Contributi

Per domande o contributi:
1. Apri un issue su GitHub
2. Consulta la documentazione in `docs/`
3. Esegui i test prima di ogni PR
4. Segui le convenzioni di commit (feat:, fix:, docs:)

---

**Prossima Milestone:** Week 8 - Database Persistence + Query Understanding LLM
**Target Date:** 2025-11-13 (7 giorni)
**Status:** âœ… Week 7 Complete, Ready for Week 8

**Progress Summary:**
- âœ… Phase 1: COMPLETO (RLCF Core)
- âœ… Week 3: COMPLETO (KG + Pipeline)
- âœ… Week 5 Day 1-2: COMPLETO (Document Ingestion)
- âœ… Week 6: COMPLETO (Orchestration Layer)
- âœ… Week 7: COMPLETO (Preprocessing Integration)
- â³ Week 8: NEXT (Database + Query Understanding LLM)

**Total LOC:** ~52,860 linee (75% del sistema completo)

---

*Documento creato automaticamente durante la sessione di sviluppo*
*Ultimo aggiornamento: 2025-11-06 (Post-Week 7 Completion)*
