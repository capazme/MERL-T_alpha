# Learning Layer Architecture (RLCF Framework)

**Implementation Status**: ğŸš§ **PARZIALMENTE IMPLEMENTATO**
**Current Version**: v0.1.0 (RLCF Core)
**Last Updated**: November 2025

**Implemented Components**:
- âœ… RLCF Core Framework: Authority scoring, feedback aggregation, bias detection (Phase 1)
- âœ… Authority Calculation: A_u(t) = Î±Â·B_u + Î²Â·T_u(t-1) + Î³Â·P_u(t) formula implemented
- âœ… Uncertainty Preservation: Shannon entropy-based disagreement quantification
- âœ… Dynamic Configuration: Hot-reload YAML configs, backup/restore
- âœ… Feedback API Endpoints: Submit feedback, batch feedback, NER corrections
- âœ… Test Suite: 68 tests for RLCF core (90%+ coverage)
- â³ Training Data Generator: Architecture defined, not yet implemented
- â³ Model Retraining Pipeline: Architecture defined, not yet automated
- â³ A/B Testing Framework: Architecture defined, not yet implemented
- â³ 4 Learning Loops: Planned for future implementation

**Code Location**: `merlt/rlcf_framework/`, `merlt/orchestration/api/routers/feedback.py`
**Tests**: `tests/rlcf/`, `tests/orchestration/test_api_feedback.py`

---

## 1. Introduction

The **Learning Layer** implements the **Reinforcement Learning from Community Feedback (RLCF)** framework, enabling MERL-T to continuously evolve based on real-world usage and expert validation. This layer consists of:

1. **Community Feedback Interface** (collect user/expert feedback)
2. **Training Data Generator** (convert feedback to training examples)
3. **Model Update Orchestrator** (retrain models, A/B test, deploy)
4. **4 Learning Loops** (Router, VectorDB Embeddings, Query Understanding, Synthesizer)

**Design Principles**:
- **Community-Driven**: Legal experts (ALIS community) drive system evolution
- **Dynamic Authority**: User authority weighted by track record (not static credentials)
- **Continuous Learning**: Weekly lightweight updates, monthly heavy retraining
- **A/B Testing**: New models deployed cautiously with performance monitoring
- **Transparent**: All feedback and model updates logged for audit

**Performance Targets**:
- Feedback collection: < 5s (user submission)
- Training data generation: < 1 hour (daily batch)
- Model retraining: < 24 hours (weekly cycle)
- A/B test duration: 7 days (10% traffic to new model)

**Reference**: See `docs/02-methodology/rlcf-framework.md` for theoretical foundation.

---

## 2. Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              USER INTERACTION WITH MERL-T              â”‚
â”‚   Query â†’ QueryContext â†’ Router â†’ Agents â†’ Experts    â”‚
â”‚                  â†’ Synthesizer â†’ Final Answer          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          COMMUNITY FEEDBACK INTERFACE                  â”‚
â”‚   User provides:                                       â”‚
â”‚   â€¢ Rating (1-5 stars)                                 â”‚
â”‚   â€¢ Corrections (structured)                           â”‚
â”‚   â€¢ Suggestions (free text)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
              Feedback Record (PostgreSQL)
              (trace_id, rating, corrections, context)
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          TRAINING DATA GENERATOR (daily batch)         â”‚
â”‚   Convert feedback â†’ training examples:                â”‚
â”‚   â€¢ Router: (context, plan, outcome) â†’ training       â”‚
â”‚   â€¢ VectorDB: (query, relevant_chunk, irrelevant_chunk) â†’ tripletâ”‚
â”‚   â€¢ Query Understanding: (query, entities, corrections) â†’ annotationâ”‚
â”‚   â€¢ Synthesizer: (expert_outputs, final_answer, rating) â†’ trainingâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
         Training Examples Database (PostgreSQL)
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       MODEL UPDATE ORCHESTRATOR (weekly/monthly)       â”‚
â”‚   â€¢ Trigger retraining when threshold met              â”‚
â”‚   â€¢ A/B test new model (10% traffic for 7 days)       â”‚
â”‚   â€¢ Monitor metrics (precision, recall, user ratings)  â”‚
â”‚   â€¢ Gradual rollout if metrics improve                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                           â”‚
         â†“                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Updated Models   â”‚       â”‚ System Logs      â”‚
â”‚ (versioned)      â”‚       â”‚ (audit trail)    â”‚
â”‚                  â”‚       â”‚                  â”‚
â”‚ â€¢ Router prompt  â”‚       â”‚ â€¢ Model versions â”‚
â”‚ â€¢ Embeddings     â”‚       â”‚ â€¢ A/B results    â”‚
â”‚ â€¢ NER model      â”‚       â”‚ â€¢ Rollouts       â”‚
â”‚ â€¢ Synthesizer    â”‚       â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Characteristics**:
- **Feedback-driven**: All learning triggered by community feedback
- **Multi-model**: 4 independent learning loops running in parallel
- **Gradual deployment**: A/B testing ensures stability
- **Traceable**: Full audit trail of model evolution

---

## 3. Community Feedback Interface

### 3.1 Feedback Collection UI

**User Journey**:

```
User receives MERL-T answer
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Answer Display with Provenance         â”‚
â”‚ â€¢ Final answer text                    â”‚
â”‚ â€¢ Sources cited (norms, case law)      â”‚
â”‚ â€¢ Expert reasoning (expandable)        â”‚
â”‚ â€¢ Confidence indicator                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
      User clicks "Provide Feedback"
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feedback Form                          â”‚
â”‚                                        â”‚
â”‚ 1. Rating: â­â­â­â­â­ (1-5 stars)        â”‚
â”‚                                        â”‚
â”‚ 2. Feedback Type (multi-select):      â”‚
â”‚    â–¡ Risposta corretta                 â”‚
â”‚    â–¡ Risposta incompleta               â”‚
â”‚    â–¡ Fonti errate                      â”‚
â”‚    â–¡ Ragionamento giuridico errato     â”‚
â”‚    â–¡ Esperti sbagliati selezionati     â”‚
â”‚                                        â”‚
â”‚ 3. Corrections (optional):             â”‚
â”‚    [Text area for detailed corrections]â”‚
â”‚                                        â”‚
â”‚ 4. Suggested Sources (optional):      â”‚
â”‚    Add norm/case: [Art. ___]          â”‚
â”‚                                        â”‚
â”‚ 5. Submit Feedback                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dynamic Authority Check                â”‚
â”‚ Calculate user_authority_score:        â”‚
â”‚ â€¢ User role (expert, lawyer, citizen)  â”‚
â”‚ â€¢ Historical accuracy of feedback      â”‚
â”‚ â€¢ Consensus with other experts         â”‚
â”‚ Output: authority_score (0.0-1.0)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Store Feedback in PostgreSQL           â”‚
â”‚ Table: answer_feedback                 â”‚
â”‚ Fields: trace_id, user_id, rating,     â”‚
â”‚         corrections, authority_score   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Feedback Form Schema**:

```json
{
  "feedback": {
    "trace_id": "SYN-20241103-abc123",
    "user_id": "uuid",
    "rating": 4,
    "feedback_types": ["risposta_incompleta", "fonti_errate"],
    "corrections": {
      "missing_sources": [
        {
          "source_type": "norm",
          "source_id": "art_1454_cc",
          "citation": "Art. 1454 c.c.",
          "relevance": "Regola complementare sulla diffida ad adempiere"
        }
      ],
      "wrong_interpretation": "L'Expert ha ignorato la distinzione tra risoluzione di diritto e risoluzione giudiziale",
      "suggested_answer": "La risposta dovrebbe distinguere tra risoluzione ex Art. 1453 (giudiziale) e Art. 1454 (di diritto)."
    },
    "suggested_sources": ["art_1454_cc"],
    "free_text_comments": "Buona risposta ma manca riferimento alla diffida ad adempiere (Art. 1454)",
    "timestamp": "2024-11-03T10:30:00Z"
  }
}
```

---

### 3.2 Dynamic Authority Calculator

**Purpose**: Weight feedback by user authority (not static credentials).

**Authority Formula**:

```
user_authority_score = (
    0.4 * role_weight +
    0.3 * historical_accuracy +
    0.2 * consensus_score +
    0.1 * reputation_score
)

Where:
- role_weight:
    â€¢ Legal expert (professor, judge, senior lawyer): 1.0
    â€¢ Practicing lawyer: 0.7
    â€¢ Law student: 0.4
    â€¢ Citizen: 0.2

- historical_accuracy:
    Count of validated feedback / Total feedback submitted
    (Feedback is "validated" when majority of experts agree)

- consensus_score:
    For this specific feedback, how many other experts agree?
    consensus_score = agreeing_experts / total_experts_who_reviewed

- reputation_score:
    Cumulative reputation from ALIS community
    (Upvotes on contributions, badges, etc.)

Output: user_authority_score âˆˆ [0.0, 1.0]
```

**Example Calculation**:

```
User: Maria Rossi, Avvocato (practicing lawyer)
- role_weight: 0.7
- historical_accuracy: 48 validated / 52 submitted = 0.923
- consensus_score: 3 agree / 4 reviewed this feedback = 0.75
- reputation_score: 850 points â†’ 0.85 (normalized)

user_authority_score = 0.4 * 0.7 + 0.3 * 0.923 + 0.2 * 0.75 + 0.1 * 0.85
                     = 0.28 + 0.277 + 0.15 + 0.085
                     = 0.792
```

**Use of Authority Score**:
- **Training Data**: High authority feedback weighted more in training
- **Model Updates**: Low authority feedback requires more consensus before acting
- **Feedback Display**: Show authority score to help users assess feedback quality

---

### 3.3 Feedback Storage Schema

**PostgreSQL Table** (from Storage Layer):

```sql
CREATE TABLE answer_feedback (
    feedback_id UUID PRIMARY KEY,
    trace_id VARCHAR(100) NOT NULL,
    user_id UUID NOT NULL,
    user_authority_score FLOAT NOT NULL,

    -- Feedback content
    rating INTEGER CHECK (rating BETWEEN 1 AND 5),
    feedback_types TEXT[], -- Array: ['risposta_incompleta', 'fonti_errate', ...]
    corrections JSONB,
    suggested_sources TEXT[],
    free_text_comments TEXT,

    -- Context (for training data generation)
    query_text TEXT NOT NULL,
    final_answer TEXT NOT NULL,
    execution_plan JSONB,
    expert_outputs JSONB,
    retrieval_result JSONB,

    -- Timestamps
    created_at TIMESTAMP DEFAULT NOW(),
    processed BOOLEAN DEFAULT false,
    processed_at TIMESTAMP
);

CREATE INDEX idx_feedback_trace_id ON answer_feedback(trace_id);
CREATE INDEX idx_feedback_rating ON answer_feedback(rating);
CREATE INDEX idx_feedback_processed ON answer_feedback(processed);
CREATE INDEX idx_feedback_authority ON answer_feedback(user_authority_score);
```

---

## 4. Training Data Generator

**Purpose**: Convert feedback into training examples for model retraining.

**Processing Flow**:

```
Daily Batch Job (runs at 2 AM)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Fetch Unprocessed Feedback          â”‚
â”‚    SELECT * FROM answer_feedback       â”‚
â”‚    WHERE processed = false             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Generate Training Examples          â”‚
â”‚    For each feedback:                  â”‚
â”‚    - Router training (context â†’ plan)  â”‚
â”‚    - VectorDB triplets (query, pos, neg)â”‚
â”‚    - Query Understanding annotations   â”‚
â”‚    - Synthesizer examples              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Quality Filtering                   â”‚
â”‚    Filter by:                          â”‚
â”‚    - user_authority_score > 0.6        â”‚
â”‚    - rating != 3 (neutral)             â”‚
â”‚    - corrections not empty             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Store Training Examples             â”‚
â”‚    INSERT INTO training_examples       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Mark Feedback as Processed          â”‚
â”‚    UPDATE answer_feedback              â”‚
â”‚    SET processed = true                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 4.1 Router Training Data

**Purpose**: Improve Router's execution plan generation.

**Training Example Schema**:

```json
{
  "example_type": "router_decision",
  "input_data": {
    "query_context": {
      "original_query": "Ãˆ valido un contratto firmato da un minorenne?",
      "entities": [...],
      "concepts": [...],
      "intent": {"primary": "validitÃ _atto"},
      "complexity": {"score": 0.62}
    },
    "enriched_context": {
      "mapped_norms": [...]
    }
  },
  "expected_output": {
    "execution_plan": {
      "retrieval_plan": {
        "api_agent": {"enabled": true, ...},
        "vectordb_agent": {"enabled": false}
      },
      "reasoning_plan": {
        "experts": ["Literal_Interpreter", "Precedent_Analyst"]
      }
    }
  },
  "outcome": {
    "actual_plan_generated": {...},
    "final_answer_rating": 2,
    "expert_correction": "Should have activated Precedent_Analyst to cite case law"
  },
  "quality_score": 0.85,
  "source_feedback_id": "uuid"
}
```

**Training Strategy**:
- **Fine-tune system prompt**: Add examples of good/bad ExecutionPlans to few-shot prompt
- **Preference learning**: Train on (query, good_plan, bad_plan) triplets using RLHF techniques
- **Evaluation**: Test new prompt on held-out feedback, measure rating improvement

---

### 4.2 Embedding Training Data (Triplets)

**Purpose**: Fine-tune VectorDB embeddings for better retrieval.

**Training Example Schema** (Contrastive Learning):

```json
{
  "example_type": "embedding_triplet",
  "input_data": {
    "anchor": "Ãˆ valido un contratto firmato da un minorenne?",
    "positive": "Art. 2 c.c. - La maggiore etÃ  Ã¨ fissata al compimento del diciottesimo anno. Con la maggiore etÃ  si acquista la capacitÃ  di compiere tutti gli atti per i quali non sia stabilita un'etÃ  diversa.",
    "negative": "Art. 1350 c.c. - Devono farsi per atto pubblico o per scrittura privata, sotto pena di nullitÃ : 1) i contratti che trasferiscono la proprietÃ  di beni immobili..."
  },
  "expected_output": {
    "anchor_to_positive_distance": "< anchor_to_negative_distance"
  },
  "quality_score": 0.92,
  "source_feedback_id": "uuid",
  "derivation": "User said 'Art. 2 c.c. is the correct source' (positive), system retrieved Art. 1350 c.c. (negative)"
}
```

**Derivation Logic**:

```
Feedback: "Fonti errate - manca Art. 2 c.c."

Derivation:
1. anchor = original query
2. positive = Art. 2 c.c. (suggested by user as correct)
3. negative = Art. 1350 c.c. (was retrieved by system but user said it's wrong)

Training: Minimize distance(anchor, positive), maximize distance(anchor, negative)
```

**Training Strategy**:
- **Contrastive loss**: Triplet margin loss
- **Hard negative mining**: Find chunks semantically similar but legally distinct
- **Batch size**: 64 triplets per batch
- **Epochs**: 3-5 epochs on accumulated RLCF data

---

### 4.3 Query Understanding Training Data

**Purpose**: Improve entity extraction, intent classification, complexity scoring.

**Training Example Schema**:

```json
{
  "example_type": "query_understanding_annotation",
  "input_data": {
    "query": "Ãˆ valido un contratto firmato da un minorenne nel 2010?"
  },
  "expected_output": {
    "entities": [
      {"text": "contratto", "type": "LEGAL_OBJECT", "start": 11, "end": 20},
      {"text": "minorenne", "type": "PERSON", "start": 35, "end": 44},
      {"text": "2010", "type": "DATE", "start": 49, "end": 53}
    ],
    "intent": {"primary": "validitÃ _atto", "confidence": 0.92},
    "complexity": {"score": 0.62}
  },
  "outcome": {
    "system_output": {
      "entities": [...], // Missing "2010" entity
      "intent": {"primary": "validitÃ _atto"},
      "complexity": {"score": 0.45} // Too low
    },
    "expert_correction": {
      "entities": "Missing DATE entity '2010'",
      "complexity": "Should be 0.62 (medium complexity) due to temporal reference"
    }
  },
  "quality_score": 0.88,
  "source_feedback_id": "uuid"
}
```

**Training Strategy**:
- **Entity extraction**: Add corrected annotations to NER fine-tuning dataset
- **Intent classification**: Retrain multi-label classifier on corrected labels
- **Complexity scoring**: Retrain Random Forest on corrected complexity scores

---

### 4.4 Synthesizer Training Data

**Purpose**: Improve answer synthesis quality (convergent vs divergent modes).

**Training Example Schema**:

```json
{
  "example_type": "synthesizer_training",
  "input_data": {
    "expert_outputs": [
      {
        "expert_type": "Literal_Interpreter",
        "interpretation": "...",
        "confidence": 0.95
      },
      {
        "expert_type": "Systemic_Teleological",
        "interpretation": "...",
        "confidence": 0.78
      }
    ],
    "synthesis_mode": "convergent",
    "query_context": {...}
  },
  "expected_output": {
    "final_answer": "Il contratto firmato da un minorenne Ã¨ annullabile (Art. 1425 c.c.). [Improved version with better synthesis]",
    "provenance": [...]
  },
  "outcome": {
    "system_output": {
      "final_answer": "Il contratto Ã¨ annullabile.", // Too brief
      "rating": 2
    },
    "expert_correction": "Answer should integrate both literal interpretation (Art. 1425) and systemic context (tutela del minore). Missing provenance for claims."
  },
  "quality_score": 0.80,
  "source_feedback_id": "uuid"
}
```

**Training Strategy**:
- **Prompt engineering**: Update synthesizer system prompt with examples of good synthesis
- **Preference learning**: Train on (expert_outputs, good_synthesis, bad_synthesis) triplets
- **Evaluation**: Measure answer quality (rating) and provenance completeness

---

## 5. Model Update Orchestrator

### 5.1 Weekly Update Cycle

**Schedule**:

```
WEEKLY CYCLE (Lightweight Updates):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monday 2 AM: Generate Training Data (daily batch)     â”‚
â”‚ â”œâ”€ Fetch unprocessed feedback from past week          â”‚
â”‚ â”œâ”€ Generate training examples                         â”‚
â”‚ â””â”€ Store in training_examples table                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monday 10 AM: Trigger Model Updates (if threshold met)â”‚
â”‚ â”œâ”€ Check: New training examples > 100?                â”‚
â”‚ â”œâ”€ YES â†’ Trigger retraining                           â”‚
â”‚ â””â”€ NO  â†’ Skip this week                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tuesday: Retraining (automated)                        â”‚
â”‚ â”œâ”€ Router: Update few-shot prompt with new examples   â”‚
â”‚ â”œâ”€ Query Understanding: Fine-tune NER on new annotationsâ”‚
â”‚ â””â”€ Synthesizer: Update prompt with new synthesis examplesâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Wednesday: A/B Test Deployment                         â”‚
â”‚ â”œâ”€ Deploy new models to 10% of traffic                â”‚
â”‚ â”œâ”€ Monitor metrics (precision, recall, user ratings)  â”‚
â”‚ â””â”€ Continue A/B test for 7 days                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Next Wednesday: Evaluate A/B Test                      â”‚
â”‚ â”œâ”€ Compare metrics: new model vs old model            â”‚
â”‚ â”œâ”€ IF new model improves â†’ Gradual rollout (50%, 100%)â”‚
â”‚ â””â”€ IF no improvement â†’ Rollback to old model          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


MONTHLY CYCLE (Heavy Retraining):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ First Monday of Month: Heavy Retraining                â”‚
â”‚ â”œâ”€ VectorDB Embeddings: Full fine-tuning (3-5 epochs) â”‚
â”‚ â”‚   on accumulated RLCF triplets (1,000-5,000 examples)â”‚
â”‚ â”‚   Duration: ~12 hours                                â”‚
â”‚ â”œâ”€ Query Understanding: Full NER retraining            â”‚
â”‚ â”‚   Duration: ~6 hours                                 â”‚
â”‚ â””â”€ Complexity Model: Retrain Random Forest             â”‚
â”‚     Duration: ~1 hour                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tuesday-Wednesday: A/B Test (same as weekly)           â”‚
â”‚ Next Tuesday: Evaluate & Rollout (same as weekly)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 5.2 A/B Testing Strategy

**Test Configuration**:

```json
{
  "ab_test_config": {
    "test_id": "uuid",
    "model_component": "router_prompt | vectordb_embeddings | ner_model | synthesizer_prompt",
    "old_model_version": "v2.3",
    "new_model_version": "v2.4",
    "traffic_split": {
      "old_model": 0.9,
      "new_model": 0.1
    },
    "duration_days": 7,
    "start_date": "2024-11-04",
    "end_date": "2024-11-11",
    "metrics_tracked": [
      "answer_quality_rating",
      "retrieval_precision",
      "retrieval_recall",
      "latency_p95",
      "error_rate"
    ]
  }
}
```

**Traffic Routing**:

```
User Query arrives
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ A/B Test Router              â”‚
â”‚ hash(user_id) % 100          â”‚
â”‚   < 10  â†’ new_model (10%)    â”‚
â”‚   >= 10 â†’ old_model (90%)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    Route to appropriate model
```

**Metrics Collection**:

```sql
CREATE TABLE ab_test_metrics (
    metric_id UUID PRIMARY KEY,
    test_id UUID NOT NULL,
    model_version VARCHAR(50) NOT NULL, -- 'v2.3' or 'v2.4'
    trace_id VARCHAR(100) NOT NULL,

    -- Metrics
    answer_quality_rating FLOAT, -- User rating (1-5)
    retrieval_precision FLOAT,   -- Relevant chunks / Retrieved chunks
    retrieval_recall FLOAT,      -- Relevant chunks / All relevant chunks
    latency_ms INTEGER,
    error_occurred BOOLEAN,

    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_ab_test_version ON ab_test_metrics(test_id, model_version);
```

**Evaluation Query**:

```sql
-- Compare new vs old model
SELECT
    model_version,
    AVG(answer_quality_rating) AS avg_rating,
    AVG(retrieval_precision) AS avg_precision,
    AVG(latency_ms) AS avg_latency_ms,
    COUNT(*) AS sample_size
FROM ab_test_metrics
WHERE test_id = $test_id
GROUP BY model_version;
```

**Decision Logic**:

```
IF new_model.avg_rating > old_model.avg_rating + 0.1  (10% improvement)
   AND new_model.avg_latency_ms < old_model.avg_latency_ms * 1.2  (< 20% slowdown)
   AND new_model.error_rate < old_model.error_rate * 1.1  (< 10% more errors)
THEN
   Gradual rollout: 10% â†’ 50% â†’ 100% (over 3 days)
ELSE
   Rollback to old model
```

---

### 5.3 Model Versioning

**Versioning Schema**:

```
Model Version Format: v{major}.{minor}.{patch}

Examples:
- v2.3.0 = Major version 2, Minor 3, Patch 0
- v2.3.1 = Bug fix (patch)
- v2.4.0 = New features (minor)
- v3.0.0 = Breaking changes (major)

Version Increments:
- Weekly updates: Patch increment (v2.3.0 â†’ v2.3.1)
- Monthly updates: Minor increment (v2.3.1 â†’ v2.4.0)
- Architecture changes: Major increment (v2.4.0 â†’ v3.0.0)
```

**Model Registry**:

```sql
CREATE TABLE model_registry (
    model_id UUID PRIMARY KEY,
    model_component VARCHAR(100) NOT NULL, -- 'router_prompt', 'vectordb_embeddings', etc.
    version VARCHAR(50) NOT NULL,
    model_artifact_url TEXT, -- S3/MinIO URL to model file
    training_data_size INTEGER,
    training_examples_ids TEXT[], -- Array of example UUIDs

    -- Performance
    validation_metrics JSONB, -- Precision, recall, etc.

    -- Deployment
    deployment_status VARCHAR(50), -- 'testing', 'deployed', 'deprecated'
    deployed_at TIMESTAMP,
    deprecated_at TIMESTAMP,

    created_at TIMESTAMP DEFAULT NOW(),

    CONSTRAINT unique_version UNIQUE(model_component, version)
);

CREATE INDEX idx_model_component ON model_registry(model_component);
CREATE INDEX idx_model_status ON model_registry(deployment_status);
```

---

## 6. Learning Loops

### 6.1 Router Learning Loop

**Objective**: Improve Router's execution plan generation based on feedback.

**Learning Process**:

```
Feedback: "Esperti sbagliati selezionati"
Correction: "Should have activated Precedent_Analyst"

Training Data Generation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: QueryContext + EnrichedContext  â”‚
â”‚ Output (system): ExecutionPlan with    â”‚
â”‚         experts = [Literal_Interpreter]â”‚
â”‚ Expected (expert): ExecutionPlan with  â”‚
â”‚         experts = [Literal_Interpreter,â”‚
â”‚                    Precedent_Analyst]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
         Few-Shot Prompt Update
         (Add example to system prompt)

System Prompt (updated):
"...
Example of good plan:
Query: 'Ãˆ valido un contratto firmato da un minorenne?'
Context: complexity=0.62, intent=validitÃ _atto
Correct Plan: Activate Literal_Interpreter + Precedent_Analyst
Rationale: Even for medium complexity, case law provides
           valuable context for validity checks.
..."
```

**Evaluation**:
- Metric: % of queries where expert selection matches expert expectations
- Target: > 85% agreement

---

### 6.2 VectorDB Embedding Loop

**Objective**: Fine-tune embeddings to improve retrieval precision/recall.

**Learning Process**:

```
Feedback: "Fonti errate - manca Art. 2 c.c."

Training Data Generation (Contrastive Triplet):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ anchor   = "Ãˆ valido un contratto      â”‚
â”‚             firmato da un minorenne?"  â”‚
â”‚ positive = Art. 2 c.c. (user suggested)â”‚
â”‚ negative = Art. 1350 c.c. (system      â”‚
â”‚            retrieved but wrong)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
    Accumulate 1,000-5,000 triplets/month
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monthly Fine-Tuning                    â”‚
â”‚ Model: multilingual-e5-large (Phase 2) â”‚
â”‚ Loss: Triplet margin loss              â”‚
â”‚ Epochs: 3-5                            â”‚
â”‚ Batch size: 64                         â”‚
â”‚ Duration: ~12 hours                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
       Updated Embedding Model
       (v2.4 â†’ v2.5)
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Re-embed All Chunks (offline)          â”‚
â”‚ â€¢ Fetch all chunks from VectorDB       â”‚
â”‚ â€¢ Re-embed with new model              â”‚
â”‚ â€¢ Update vectors in VectorDB           â”‚
â”‚ Duration: ~48 hours (1M chunks)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Evaluation**:
- Metric: Precision@10, Recall@10, MRR@10 (Mean Reciprocal Rank)
- Target: +5% improvement per monthly cycle

---

### 6.3 Query Understanding Loop

**Objective**: Improve entity extraction, intent classification, complexity scoring.

**Learning Process**:

```
Feedback: "Intent classification wrong"
Correction: "Should be 'interpretazione_norma' not 'validitÃ _atto'"

Training Data Generation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: Query                           â”‚
â”‚ Output (system): intent = 'validitÃ _atto' (confidence: 0.85)â”‚
â”‚ Expected (expert): intent = 'interpretazione_norma'â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
    Accumulate 100-500 annotations/month
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monthly Fine-Tuning                    â”‚
â”‚ â€¢ NER Model: BERT fine-tuned on        â”‚
â”‚   corrected entity annotations         â”‚
â”‚ â€¢ Intent Classifier: Multi-label BERT  â”‚
â”‚   retrained on corrected intents       â”‚
â”‚ â€¢ Complexity Model: Random Forest      â”‚
â”‚   retrained on corrected scores        â”‚
â”‚ Duration: ~6 hours                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Evaluation**:
- **NER**: F1 score on entity extraction
- **Intent**: Accuracy on intent classification
- **Complexity**: Mean absolute error (MAE) on complexity score
- Target: F1 > 0.90, Accuracy > 0.85, MAE < 0.1

---

### 6.4 Synthesizer Loop

**Objective**: Improve answer synthesis quality (convergent/divergent modes).

**Learning Process**:

```
Feedback: "Risposta troppo breve, manca contesto"
Rating: 2/5

Training Data Generation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: Expert outputs (2 experts)      â”‚
â”‚ Output (system): "Il contratto Ã¨       â”‚
â”‚         annullabile." (1 sentence)     â”‚
â”‚ Expected (expert): "Il contratto       â”‚
â”‚         firmato da un minorenne Ã¨      â”‚
â”‚         annullabile (Art. 1425 c.c.).  â”‚
â”‚         La norma prevede... [3 paragraphs]"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
    Accumulate 50-200 examples/month
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monthly Prompt Update                  â”‚
â”‚ â€¢ Add examples of good synthesis       â”‚
â”‚   to system prompt                     â”‚
â”‚ â€¢ Emphasize provenance completeness    â”‚
â”‚ â€¢ Provide counter-examples (bad        â”‚
â”‚   synthesis = too brief)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Evaluation**:
- Metric: User rating (1-5), answer length, provenance completeness
- Target: Avg rating > 4.0, provenance completeness > 95%

---

## 7. Technology Mapping

### 7.1 RLCF Infrastructure

| Component | Technology | Rationale |
|-----------|-----------|-----------|
| **Feedback Storage** | PostgreSQL | ACID compliance, JSONB for flexible schemas |
| **Training Data Processing** | Celery + RabbitMQ | Async task queue for batch jobs |
| **Model Training** | Python + PyTorch/Transformers | Standard ML stack for NLP |
| **A/B Testing** | Custom traffic router (Python) | Deterministic routing based on user_id hash |
| **Model Registry** | PostgreSQL + MinIO/S3 | Metadata in PostgreSQL, artifacts in object storage |

---

### 7.2 Model Training Tools

| Model | Training Framework | Infrastructure |
|-------|-------------------|---------------|
| **VectorDB Embeddings** | Sentence-Transformers (PyTorch) | GPU instance (A100, 24 hours) |
| **NER Model** | Hugging Face Transformers | GPU instance (V100, 6 hours) |
| **Intent Classifier** | Scikit-learn / Transformers | CPU instance (4 cores, 2 hours) |
| **Complexity Model** | Scikit-learn (Random Forest) | CPU instance (2 cores, 1 hour) |

---

## 8. Docker Compose Architecture

### 8.1 Service Definitions

```yaml
version: '3.8'

services:
  # RLCF Feedback API
  rlcf-feedback-api:
    build: ./services/rlcf-feedback-api
    ports:
      - "8040:8000"
    environment:
      - POSTGRES_URI=postgresql://merl_t:${POSTGRES_PASSWORD}@postgres:5432/merl_t
      - AUTH_SECRET_KEY=${AUTH_SECRET_KEY}
    depends_on:
      - postgres
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Training Data Generator (Celery Worker)
  training-data-generator:
    build: ./services/training-data-generator
    environment:
      - CELERY_BROKER_URL=amqp://rabbitmq:5672
      - POSTGRES_URI=postgresql://merl_t:${POSTGRES_PASSWORD}@postgres:5432/merl_t
    depends_on:
      - rabbitmq
      - postgres
    deploy:
      replicas: 2

  # Model Update Orchestrator (Celery Beat Scheduler)
  model-update-orchestrator:
    build: ./services/model-update-orchestrator
    environment:
      - CELERY_BROKER_URL=amqp://rabbitmq:5672
      - POSTGRES_URI=postgresql://merl_t:${POSTGRES_PASSWORD}@postgres:5432/merl_t
      - MODEL_REGISTRY_S3_BUCKET=merl-t-models
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    depends_on:
      - rabbitmq
      - postgres

  # A/B Test Router (Traffic Splitter)
  ab-test-router:
    build: ./services/ab-test-router
    ports:
      - "8041:8000"
    environment:
      - POSTGRES_URI=postgresql://merl_t:${POSTGRES_PASSWORD}@postgres:5432/merl_t
      - ROUTER_V2_3_URL=http://router-v2-3:8000
      - ROUTER_V2_4_URL=http://router-v2-4:8000
      - AB_TEST_CONFIG_TABLE=ab_test_config
    depends_on:
      - postgres

  # PostgreSQL (from Storage Layer)
  postgres:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=merl_t
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=merl_t
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # RabbitMQ (from Storage Layer)
  rabbitmq:
    image: rabbitmq:3.12-management
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq

volumes:
  postgres_data:
  rabbitmq_data:
```

---

## 9. Performance Characteristics

### 9.1 Latency

| Operation | Latency | Frequency |
|-----------|---------|-----------|
| **Feedback submission** | < 5s | Per user interaction |
| **Training data generation** | ~1 hour | Daily (batch) |
| **Weekly model update** | ~6 hours | Weekly |
| **Monthly embedding retraining** | ~12 hours | Monthly |
| **Re-embedding corpus** | ~48 hours | After embedding update |
| **A/B test evaluation** | ~10 minutes | Weekly |

---

### 9.2 Throughput

| Operation | Throughput | Conditions |
|-----------|-----------|-----------|
| **Feedback collection** | 1,000 submissions/day | Avg user base |
| **Training data generation** | 500 examples/hour | 2 Celery workers |
| **Model training** | 1 model/week | GPU instance |

---

## 10. Cross-References

### Section 02 Methodology
- **RLCF Framework**: `docs/02-methodology/rlcf-framework.md`
  - Â§2: Dynamic Authority Calculation
  - Â§3: Feedback Collection Interface
  - Â§4: Training Data Generation
  - Â§5: Model Update Orchestration

### Section 03 Architecture
- **All Layers**: RLCF feedback loop integrated across all components
  - Preprocessing Layer: Query Understanding evolution
  - Orchestration Layer: Router learning
  - Reasoning Layer: Expert/Synthesizer evolution
  - Storage Layer: Embedding fine-tuning

---

## 11. Appendices

### A. Feedback Quality Metrics

**Metrics Tracked**:
- **Feedback volume**: Submissions per day/week
- **Feedback distribution**: Rating distribution (1-5 stars)
- **Authority distribution**: User authority score distribution
- **Correction rate**: % of feedback with structured corrections
- **Consensus rate**: % of feedback validated by multiple experts

---

### B. Model Performance Tracking

**Metrics Dashboard**:
- **Router**: Plan effectiveness (correlation plan â†” rating)
- **VectorDB**: Precision@10, Recall@10, MRR@10
- **Query Understanding**: NER F1, Intent accuracy, Complexity MAE
- **Synthesizer**: Avg user rating, Provenance completeness

**Alert Thresholds**:
- Rating drop > 0.5 â†’ Alert dev team
- Precision drop > 10% â†’ Rollback model
- Latency increase > 50% â†’ Investigate bottleneck

---

**Document Version**: 1.0
**Last Updated**: 2024-11-03
**Status**: âœ… Complete
