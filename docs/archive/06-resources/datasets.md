# Datasets for MERL-T

## 1. Introduction

The MERL-T project relies on a diverse set of high-quality datasets for retrieval, fine-tuning, and evaluation. Our data strategy is designed to create a rich and comprehensive knowledge base that reflects the complexity and nuances of the legal domain. This document outlines the key datasets used in the project.

## 2. Core Datasets for Retrieval (RAG)

These datasets form the backbone of our Retrieval-Augmented Generation (RAG) pipeline. They are used to populate the ChromaDB Vector Store and the Neo4j Knowledge Graph, providing the context that the expert LLM modules use to generate answers.

### A. Italian Legal Codes

-   **Content**: The full text of the main Italian codes, including the Codice Civile, Codice Penale, Codice di Procedura Civile, and Codice di Procedura Penale.
-   **Source**: Publicly available sources, with a focus on official and up-to-date versions.
-   **Use**: This forms the primary legal source material for the system. The text is chunked and embedded for the Vector Store, and the articles and their relationships are modeled in the Knowledge Graph.

### B. University Manuals

-   **Content**: A selection of authoritative university-level textbooks and manuals covering fundamental areas of Italian law (e.g., private law, constitutional law, criminal law).
-   **Source**: To be acquired, with a preference for open-source or permissively licensed materials where possible.
-   **Use**: These texts provide doctrinal context and explanations of legal principles, which are essential for answering theoretical questions. They are a key component of the fine-tuning corpus for the "Principles Expert" LLM.

### C. Case Law

-   **Content**: A collection of key judgments (massime) from the highest Italian courts, including the Corte di Cassazione, Consiglio di Stato, and Corte Costituzionale.
-   **Source**: Publicly available legal databases and APIs.
-   **Use**: This provides the jurisprudential context, allowing the system to understand how laws are interpreted and applied in practice. This data is crucial for both the RAG context and for fine-tuning.

## 3. Fine-tuning Datasets for Expert Modules

To create our specialized "expert" LLMs, we will use curated datasets for fine-tuning.

### A. Principles Expert LLM Corpus

-   **Content**: A corpus of texts focused on legal theory, principles, and doctrine. This will be composed of selections from the university manuals, as well as key decisions from the Corte Costituzionale, the European Court of Justice (CGUE), and the European Court of Human Rights (CEDU).
-   **Use**: This dataset will be used to fine-tune a base LLM to create the "Principles Expert," which specializes in answering abstract and theoretical legal questions.

### B. Rules Expert LLM Corpus

-   **Content**: This dataset will be composed of question-answer pairs where the answer is directly supported by a specific legal text. This will be generated by combining legal questions with the corresponding articles from the legal codes and case law.
-   **Use**: This dataset will be used to fine-tune a base LLM to create the "Rules Expert," which will be optimized for Retrieval-Augmented Generation (RAG) and for answering questions based strictly on the provided context.

## 4. The RLCF Dataset (Community-Generated)

This is the most unique and valuable dataset in the MERL-T ecosystem. It is not a static dataset but is continuously generated and refined by the ALIS community through the RLCF process.

-   **Content**: The RLCF dataset consists of the feedback provided by legal experts on the final answers generated by the MERL-T pipeline. Each data point includes:
    -   The initial user query.
    -   The final answer generated by the system.
    -   The detailed feedback from one or more experts, including corrections, ratings, alternative positions, and reasoning.
    -   The authority score of the expert(s) who provided the feedback.
-   **Use**: This dataset is the lifeblood of the MERL-T system. It is used to train and continuously improve the two core trainable agents in the pipeline:
    1.  **The MoE Router**: The feedback teaches the Router which execution plan is most appropriate for which type of query.
    2.  **The MoE Synthesizer**: The feedback teaches the Synthesizer how to best combine the outputs of the expert LLM modules to create a high-quality final answer.

This community-driven approach ensures that the MERL-T system not only starts from a high-quality knowledge base but also learns and adapts over time, continuously improving its reasoning and synthesis capabilities based on the collective intelligence of the legal community.
