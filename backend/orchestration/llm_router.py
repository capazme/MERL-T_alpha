"""
LLM Router - Week 6 Day 1
=========================

100% LLM-based decision engine for MERL-T pipeline.

The Router analyzes query context and generates an ExecutionPlan that determines:
- Which retrieval agents to activate (KG, API, VectorDB)
- Which reasoning experts to involve (Literal, Systemic, Principles, Precedent)
- Iteration strategy (refinement cycles)

**NO hardcoded rules** - all decisions made by LLM reasoning.

Usage:
    from backend.orchestration.llm_router import RouterService, ExecutionPlan

    router = RouterService()

    plan = await router.generate_execution_plan(
        query_context={...},
        enriched_context={...}
    )

    print(plan.retrieval_plan.kg_agent.enabled)
    print(plan.reasoning_plan.experts)
"""

import json
import logging
from typing import Dict, Any, List, Optional, Literal
from datetime import datetime
from pathlib import Path

from pydantic import BaseModel, Field, field_validator

# Import OpenRouter service from Phase 1
from backend.rlcf_framework.ai_service import openrouter_service

# Import configuration
from backend.orchestration.config import get_orchestration_config


logger = logging.getLogger(__name__)


# ==============================================
# Pydantic Models for ExecutionPlan
# ==============================================

class AgentTask(BaseModel):
    """Base class for agent task"""
    task_type: str
    priority: Literal["high", "medium", "low"] = Field(default="medium")
    params: Dict[str, Any] = Field(default_factory=dict)


class KGAgentTasks(BaseModel):
    """KG Agent tasks"""
    enabled: bool = Field(default=False)
    tasks: List[AgentTask] = Field(default_factory=list)
    rationale: str = Field(default="")


class APIAgentTask(BaseModel):
    """API Agent task"""
    task_type: Literal["fetch_full_text", "fetch_versions", "fetch_metadata"]
    norm_references: List[str] = Field(default_factory=list)
    priority: Literal["high", "medium", "low"] = Field(default="medium")


class APIAgentTasks(BaseModel):
    """API Agent tasks"""
    enabled: bool = Field(default=False)
    tasks: List[APIAgentTask] = Field(default_factory=list)
    rationale: str = Field(default="")


class VectorDBAgentTask(BaseModel):
    """VectorDB Agent task"""
    task_type: Literal["semantic_search", "hybrid_search", "filtered_search"]
    query_text: str
    filters: Dict[str, Any] = Field(default_factory=dict)
    priority: Literal["high", "medium", "low"] = Field(default="medium")


class VectorDBAgentTasks(BaseModel):
    """VectorDB Agent tasks"""
    enabled: bool = Field(default=False)
    tasks: List[VectorDBAgentTask] = Field(default_factory=list)
    rationale: str = Field(default="")


class RetrievalPlan(BaseModel):
    """Plan for retrieval agents"""
    kg_agent: KGAgentTasks = Field(default_factory=KGAgentTasks)
    api_agent: APIAgentTasks = Field(default_factory=APIAgentTasks)
    vectordb_agent: VectorDBAgentTasks = Field(default_factory=VectorDBAgentTasks)


class ExpertSelection(BaseModel):
    """Expert selection"""
    expert_type: Literal[
        "literal_interpreter",
        "systemic_teleological",
        "principles_balancer",
        "precedent_analyst"
    ]
    activation_rationale: str
    priority: Literal["high", "medium", "low"] = Field(default="medium")


class ReasoningPlan(BaseModel):
    """Plan for reasoning experts"""
    experts: List[ExpertSelection] = Field(default_factory=list)
    synthesis_mode: Literal["convergent", "divergent"] = Field(default="convergent")
    synthesis_rationale: str = Field(default="")

    @field_validator('experts')
    @classmethod
    def validate_experts(cls, experts: List[ExpertSelection]) -> List[ExpertSelection]:
        """Ensure at least 1 expert is selected"""
        if len(experts) == 0:
            raise ValueError("At least one reasoning expert must be selected")
        return experts


class IterationStrategy(BaseModel):
    """Iteration strategy"""
    estimated_iterations: int = Field(default=1, ge=1, le=3)
    refine_on_low_confidence: bool = Field(default=False)
    refine_on_disagreement: bool = Field(default=False)
    refine_on_missing_info: bool = Field(default=False)
    rationale: str = Field(default="")


class ExecutionPlan(BaseModel):
    """Complete execution plan generated by LLM Router"""
    trace_id: str
    rationale: str  # Router's reasoning for this plan (Italian)

    retrieval_plan: RetrievalPlan
    reasoning_plan: ReasoningPlan
    iteration_strategy: IterationStrategy

    # Metadata
    generated_at: str = Field(default_factory=lambda: datetime.utcnow().isoformat())
    router_model: str = Field(default="")
    router_temperature: float = Field(default=0.1)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        return self.model_dump()

    @classmethod
    def from_json(cls, json_str: str) -> "ExecutionPlan":
        """Create ExecutionPlan from JSON string"""
        data = json.loads(json_str)
        return cls(**data)


# ==============================================
# Router Service
# ==============================================

class RouterService:
    """
    LLM Router service for generating execution plans.

    Uses OpenRouter (Claude 3.5 Sonnet by default) to analyze query context
    and generate structured ExecutionPlan via prompt engineering.
    """

    def __init__(
        self,
        ai_service: Optional[Any] = None,
        config: Optional[Any] = None
    ):
        """
        Initialize Router Service.

        Args:
            ai_service: OpenRouterService instance (from Phase 1). If None, uses global instance.
            config: OrchestrationConfig. If None, loads from global config.
        """
        self.config = config or get_orchestration_config()
        self.ai_service = ai_service or openrouter_service

        # Load prompt template
        self.prompt_template = self._load_prompt_template(
            self.config.llm_router.prompt_template
        )

        logger.info(
            f"RouterService initialized with model: {self.config.llm_router.model}"
        )

    def _load_prompt_template(self, template_name: str) -> str:
        """
        Load prompt template from file.

        Args:
            template_name: Template name (e.g., "router_v1")

        Returns:
            Prompt template string
        """
        prompt_dir = Path(__file__).parent / "prompts"
        prompt_file = prompt_dir / f"{template_name}.txt"

        if not prompt_file.exists():
            raise FileNotFoundError(f"Prompt template not found: {prompt_file}")

        with open(prompt_file, 'r', encoding='utf-8') as f:
            return f.read()

    async def generate_execution_plan(
        self,
        query_context: Dict[str, Any],
        enriched_context: Dict[str, Any],
        trace_id: Optional[str] = None
    ) -> ExecutionPlan:
        """
        Generate ExecutionPlan via LLM reasoning.

        Args:
            query_context: Query understanding result
                {
                    "original_query": str,
                    "intent": str,
                    "intent_confidence": float,
                    "norm_references": List[Dict],
                    "legal_concepts": List[str],
                    "entities": Dict,
                    "complexity": str
                }
            enriched_context: KG enrichment result
                {
                    "norms": {"count": int, "sources": List[str]},
                    "sentenze": {"count": int, ...},
                    "dottrina": {...},
                    "contributions": {...},
                    "rlcf_votes": {...},
                    "cache_hit": bool
                }
            trace_id: Optional trace ID for logging

        Returns:
            ExecutionPlan with retrieval_plan, reasoning_plan, iteration_strategy

        Raises:
            ValueError: If LLM returns invalid JSON
        """
        trace_id = trace_id or f"router-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}"

        logger.info(f"[{trace_id}] Generating execution plan...")

        # Build prompt
        prompt = self._build_prompt(query_context, enriched_context)

        # Call OpenRouter
        try:
            response_text = await self.ai_service.generate_completion(
                prompt=prompt,
                system_prompt="You are an expert legal AI router. Respond ONLY with valid JSON following the schema provided.",
                model=self.config.llm_router.model,
                temperature=self.config.llm_router.temperature,
                max_tokens=self.config.llm_router.max_tokens
            )

            # Parse JSON response
            execution_plan = self._parse_llm_response(
                response_text,
                trace_id,
                query_context,
                enriched_context
            )

            # Add metadata
            execution_plan.router_model = self.config.llm_router.model
            execution_plan.router_temperature = self.config.llm_router.temperature

            logger.info(
                f"[{trace_id}] Execution plan generated: "
                f"{len(execution_plan.reasoning_plan.experts)} experts, "
                f"{execution_plan.iteration_strategy.estimated_iterations} iterations"
            )

            # Log decision (for RLCF feedback)
            if self.config.llm_router.log_decisions:
                self._log_decision(execution_plan, query_context)

            return execution_plan

        except Exception as e:
            logger.error(f"[{trace_id}] Router LLM call failed: {str(e)}")

            # Fallback strategy
            if self.config.llm_router.fallback_strategy == "default_plan":
                logger.warning(f"[{trace_id}] Using fallback default plan")
                return self._generate_fallback_plan(trace_id, query_context, enriched_context)
            else:
                raise

    def _build_prompt(
        self,
        query_context: Dict[str, Any],
        enriched_context: Dict[str, Any]
    ) -> str:
        """
        Build prompt for LLM Router.

        Args:
            query_context: Query understanding result
            enriched_context: KG enrichment result

        Returns:
            Complete prompt string
        """
        # Format contexts as JSON
        query_context_json = json.dumps(query_context, indent=2, ensure_ascii=False)
        enriched_context_json = json.dumps(enriched_context, indent=2, ensure_ascii=False)

        # Fill template
        prompt = self.prompt_template.format(
            query_context=query_context_json,
            enriched_context=enriched_context_json
        )

        return prompt

    def _parse_llm_response(
        self,
        response: str,
        trace_id: str,
        query_context: Dict[str, Any],
        enriched_context: Dict[str, Any]
    ) -> ExecutionPlan:
        """
        Parse LLM response into ExecutionPlan.

        Args:
            response: Raw LLM response (should be JSON)
            trace_id: Trace ID for logging
            query_context: Original query context
            enriched_context: Original enriched context

        Returns:
            ExecutionPlan

        Raises:
            ValueError: If JSON invalid or doesn't match schema
        """
        try:
            # Extract JSON from response (LLM might add markdown formatting)
            json_str = self._extract_json(response)

            # Parse JSON
            plan_dict = json.loads(json_str)

            # Ensure trace_id is set
            plan_dict["trace_id"] = trace_id

            # Validate and create ExecutionPlan
            execution_plan = ExecutionPlan(**plan_dict)

            return execution_plan

        except json.JSONDecodeError as e:
            logger.error(f"[{trace_id}] Invalid JSON from LLM: {str(e)}")
            logger.debug(f"LLM response: {response[:500]}...")
            raise ValueError(f"Router LLM returned invalid JSON: {str(e)}")

        except Exception as e:
            logger.error(f"[{trace_id}] Failed to parse execution plan: {str(e)}")
            raise ValueError(f"Router LLM response doesn't match schema: {str(e)}")

    def _extract_json(self, response: str) -> str:
        """
        Extract JSON from LLM response.

        LLM might wrap JSON in markdown code blocks like:
        ```json
        {...}
        ```

        Args:
            response: Raw LLM response

        Returns:
            Clean JSON string
        """
        # Remove markdown code blocks
        response = response.strip()

        if response.startswith("```json"):
            response = response[7:]  # Remove ```json
        elif response.startswith("```"):
            response = response[3:]  # Remove ```

        if response.endswith("```"):
            response = response[:-3]  # Remove trailing ```

        return response.strip()

    def _generate_fallback_plan(
        self,
        trace_id: str,
        query_context: Dict[str, Any],
        enriched_context: Dict[str, Any]
    ) -> ExecutionPlan:
        """
        Generate safe fallback ExecutionPlan when LLM fails.

        Uses simple heuristics to create a minimal working plan.

        Args:
            trace_id: Trace ID
            query_context: Query context
            enriched_context: Enriched context

        Returns:
            Safe fallback ExecutionPlan
        """
        logger.warning(f"[{trace_id}] Generating fallback execution plan")

        intent = query_context.get("intent", "norm_explanation")
        has_norm_refs = len(query_context.get("norm_references", [])) > 0

        # Default: API agent (fetch norm text) + Literal Interpreter
        return ExecutionPlan(
            trace_id=trace_id,
            rationale="Fallback plan: LLM router non disponibile, usando piano di default",

            retrieval_plan=RetrievalPlan(
                kg_agent=KGAgentTasks(enabled=False),
                api_agent=APIAgentTasks(
                    enabled=has_norm_refs,
                    tasks=[
                        APIAgentTask(
                            task_type="fetch_full_text",
                            norm_references=query_context.get("norm_references", []),
                            priority="high"
                        )
                    ] if has_norm_refs else [],
                    rationale="Recupero testo norme (fallback)"
                ),
                vectordb_agent=VectorDBAgentTasks(enabled=False)
            ),

            reasoning_plan=ReasoningPlan(
                experts=[
                    ExpertSelection(
                        expert_type="literal_interpreter",
                        activation_rationale="Interpretazione letterale (fallback)",
                        priority="high"
                    )
                ],
                synthesis_mode="convergent",
                synthesis_rationale="Solo un esperto (fallback)"
            ),

            iteration_strategy=IterationStrategy(
                estimated_iterations=1,
                refine_on_low_confidence=False,
                refine_on_disagreement=False,
                refine_on_missing_info=False,
                rationale="Piano di fallback: singola iterazione"
            ),

            router_model="fallback",
            router_temperature=0.0
        )

    def _log_decision(
        self,
        execution_plan: ExecutionPlan,
        query_context: Dict[str, Any]
    ) -> None:
        """
        Log router decision for RLCF feedback collection.

        Args:
            execution_plan: Generated execution plan
            query_context: Original query context
        """
        # TODO: Week 7+ - Save to database for RLCF feedback collection
        # Legal experts can review router decisions and provide corrections

        log_entry = {
            "trace_id": execution_plan.trace_id,
            "timestamp": execution_plan.generated_at,
            "query": query_context.get("original_query", ""),
            "intent": query_context.get("intent", ""),
            "router_rationale": execution_plan.rationale,
            "experts_selected": [e.expert_type for e in execution_plan.reasoning_plan.experts],
            "iteration_estimate": execution_plan.iteration_strategy.estimated_iterations,
            "model": execution_plan.router_model
        }

        logger.info(f"Router decision logged: {log_entry}")


# ==============================================
# Exports
# ==============================================

__all__ = [
    "ExecutionPlan",
    "RetrievalPlan",
    "ReasoningPlan",
    "IterationStrategy",
    "RouterService",
    "ExpertSelection",
    "KGAgentTasks",
    "APIAgentTasks",
    "VectorDBAgentTasks",
]
